{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说明：  \n",
    "本文档使用的数据来自于 Data clean 1 里 的填充过缺失值的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=5> Contents： </font>  \n",
    "1. 准备数据集  \n",
    "2. 过拟合XGB模型  \n",
    "3. GridSearchCV进行超参数交叉验证  \n",
    "&ensp;&ensp;&ensp;&ensp;3.1 自定义网络搜索函数  \n",
    "4. 交叉验证  \n",
    "5. 训练最终XGB模型并预测未知样本集  \n",
    "6. 提交结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "# from scipy import special\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials,rand\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "import time\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_iteration</th>\n",
       "      <th>model_num</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>validation_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>0.727055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.736062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.890393</td>\n",
       "      <td>0.756073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.962529</td>\n",
       "      <td>0.742586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.884069</td>\n",
       "      <td>0.734300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_iteration  model_num  train_auc  validation_auc\n",
       "1               6          1   0.970433        0.727055\n",
       "2               2          2   0.924242        0.736062\n",
       "3               1          3   0.890393        0.756073\n",
       "4               5          4   0.962529        0.742586\n",
       "5               1          5   0.884069        0.734300"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. GridSearchCV 进行超参数交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 自定义网格搜索函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Combination_enum(d):   # d 是参数字典\n",
    "    \n",
    "    K=[]                   # K 为参数目录\n",
    "    V=[]                   # V 为每个参数可能取的值。二维list，与 K 对应。\n",
    "    for k,v in d.items():\n",
    "        K.append(k)\n",
    "        V.append(v)\n",
    "    \n",
    "    p = len(K)-1           # p 是最后一个参数的索引\n",
    "    L=[]                   # L 用来综合得到的组合\n",
    "    e=[]                   # e 提供初始的组合，是空集合\n",
    "    \n",
    "    def fun3(p,e):\n",
    "        nonlocal L\n",
    "        if p==-1:\n",
    "            L.append(copy.deepcopy(e))   # 若 p==-1，说明所有参数都取遍了，\n",
    "            return                       # 得到了一个组合，可以添加到 L 里了\n",
    "        for i in range(len(V[p])):\n",
    "            f = []\n",
    "            for j in range(len(V[p])):\n",
    "                f.append(copy.deepcopy(e))\n",
    "            for j in range(len(V[p])):\n",
    "                f[j].append(V[p][i])\n",
    "            fun3(p-1,f[i])\n",
    "    fun3(p,e)      # 采用了递归调用\n",
    "    \n",
    "    comb = L\n",
    "    param_names = [i for i in reversed(K)] # 需要把 K 反序排列\n",
    "    df = pd.DataFrame(comb,columns = param_names)   \n",
    "    return comb,param_names, df\n",
    "\n",
    "def myGridSearchCV2(XGB_param,Combination_enum,param_names,X,\n",
    "                    y,K,random_state):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=K,shuffle=True,random_state=random_state) \n",
    "    Xt = []\n",
    "    Yt = []\n",
    "    Xv = []\n",
    "    Yv = []\n",
    "    for train_index, validation_index in skf.split(X,y):  \n",
    "        Xt.append(X_tr_train.values[train_index])\n",
    "        Yt.append(y_tr_train.values[train_index])\n",
    "        Xv.append(X_tr_train.values[validation_index])\n",
    "        Yv.append(y_tr_train.values[validation_index])\n",
    "        \n",
    "    records = []  \n",
    "    Info = []    \n",
    "    for l in  range(len(Combination_enum)):  \n",
    "        paramcombdict = {}\n",
    "        for i in range(len(param_names)):\n",
    "            paramcombdict[param_names[i]]=Combination_enum[l][i] \n",
    "    \n",
    "        \n",
    "        XGB_param_fix = XGB_param          \n",
    "        XGB_param_fix.update(paramcombdict) \n",
    "                \n",
    "        Scores=[]\n",
    "        Models=[XGBClassifier(**XGB_param_fix) for i in range(len(Xt))] \n",
    "        for i in range(len(Xt)):      \n",
    "            Models[i].fit(Xt[i],Yt[i], eval_set = [(Xt[i],Yt[i]),\n",
    "                                                   ( Xv[i],Yv[i])],\n",
    "                       eval_metric =[\"logloss\",\"auc\"] ,\n",
    "                          early_stopping_rounds = 10,verbose = True)\n",
    "            \n",
    "            # 为 K 个模型中的每个收集信息\n",
    "            n = Models[i].best_iteration  \n",
    "            r = Models[i].evals_result()\n",
    "            Infoi = []\n",
    "            Infoi.append(paramcombdict)                  # 此超参数值 c \n",
    "            Infoi.append(i+1)                            \n",
    "            Infoi.append(n)                              # 此模型的最佳轮数\n",
    "            Infoi.append(r[\"validation_0\"][\"auc\"][n])    \n",
    "            Infoi.append(r[\"validation_1\"][\"auc\"][n])   \n",
    "            Info.append(Infoi)\n",
    "            \n",
    "            Scores.append(Models[i].best_score)        \n",
    "            print(\"--------------------------------\")\n",
    "        \n",
    "        print(\"When param is %s, five scores are :\" % paramcombdict)\n",
    "        print(Scores)\n",
    "        print(\"--------------------------------\")\n",
    "        print(\"--------------------------------\")\n",
    "        print(\"--------------------------------\")\n",
    "        \n",
    "        records.append([paramcombdict,np.mean(Scores)])\n",
    "    \n",
    "    Info = pd.DataFrame(Info,columns=[\"paramcombdict\",\"model_round\",\n",
    "                                      \"best_iteration\",\n",
    "                                      \"train_auc\",\"validation_auc\"])\n",
    "    records = pd.DataFrame(records,columns=[\"paramcombdict\",\"mean_auc\"]\n",
    "                          ).sort_values(by=\"mean_auc\",ascending=False)\n",
    "    \n",
    "    return Info, records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固定参数\n",
    "\n",
    "XGB_param2 = dict(                  \n",
    "    n_estimators=1000,       # 树的个数--1000棵树建立xgboost\n",
    "    silent = False,          # 此为默认设置，打印running boosting时的message。这个打印是打印到 后台 cmd或 powershell里。\n",
    "    objective='binary:logistic',        # 指定损失函数\n",
    "    # nthread = -1,             # 此为默认设置，并行线程数。\n",
    "    scale_pos_weight = scale_pos_weight_value,   # 设置正类别样本的权重。解决正反样本个数不平衡的问题。\n",
    "    base_score = 0.5,         # 此为默认设置，\n",
    "    seed = 6,                           # 随机数，因为涉及到随机采样等随机过程。\n",
    "    missing = np.nan,                    # XGB是能处理带缺失值的数据的模型，所以需要指出数据集中用什么代表缺失值。不过我的数据无缺失。\n",
    "    max_delta_step = 0,        # 此为默认设置，每棵树权重改变的最大步长。\n",
    "    colsample_bylevel = 1,    # 此为默认设置，树的每一级的每一次分裂时，对特征的采样比例。因为要调节的超参数已有colsample_bytree，所以就不调节colsample_bylevel了\n",
    "    reg_alpha = 0,                      # （默认此为默认设置，L1正则项系数。\n",
    "    reg_lambda = 1,                     # （默认）此为默认设置，L2正则项系数。\n",
    "    gamma=0,            # 设置节点划分要达到的loss减小量\n",
    "    min_child_weight = 1,               # （默认）叶子节点最小实例数据权重和\n",
    "    colsample_btree=1,                  # （默认）训练每棵树时特征采样的比例\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要调节的超参数\n",
    "\n",
    "XGB_param_grid2 = dict(\n",
    "    learning_rate=[0.1,0.2,0.3,0.5],         # 提升树的学习率 \n",
    "    max_depth=[1,3,5,7,9],                        # 树的最大深度\n",
    "    subsample=[0.8,1.0],            # 训练每棵树时实例数据随机采样的比例\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsample</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subsample  max_depth  learning_rate\n",
       "0         0.8          1            0.1\n",
       "1         0.8          1            0.2\n",
       "2         0.8          1            0.3\n",
       "3         0.8          1            0.5\n",
       "4         0.8          3            0.1\n",
       "5         0.8          3            0.2\n",
       "6         0.8          3            0.3\n",
       "7         0.8          3            0.5\n",
       "8         0.8          5            0.1\n",
       "9         0.8          5            0.2\n",
       "10        0.8          5            0.3\n",
       "11        0.8          5            0.5\n",
       "12        0.8          7            0.1\n",
       "13        0.8          7            0.2\n",
       "14        0.8          7            0.3\n",
       "15        0.8          7            0.5\n",
       "16        0.8          9            0.1\n",
       "17        0.8          9            0.2\n",
       "18        0.8          9            0.3\n",
       "19        0.8          9            0.5\n",
       "20        1.0          1            0.1\n",
       "21        1.0          1            0.2\n",
       "22        1.0          1            0.3\n",
       "23        1.0          1            0.5\n",
       "24        1.0          3            0.1\n",
       "25        1.0          3            0.2\n",
       "26        1.0          3            0.3\n",
       "27        1.0          3            0.5\n",
       "28        1.0          5            0.1\n",
       "29        1.0          5            0.2\n",
       "30        1.0          5            0.3\n",
       "31        1.0          5            0.5\n",
       "32        1.0          7            0.1\n",
       "33        1.0          7            0.2\n",
       "34        1.0          7            0.3\n",
       "35        1.0          7            0.5\n",
       "36        1.0          9            0.1\n",
       "37        1.0          9            0.2\n",
       "38        1.0          9            0.3\n",
       "39        1.0          9            0.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb,param_names,param_grid_df = Combination_enum(XGB_param_grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 交叉验证。对每一对超参数组合进行检查\n",
    "\n",
    "timestart=time.time()\n",
    "Info, records = myGridSearchCV2(XGB_param2,comb,param_names,\n",
    "                X_tr_train.values,y_tr_train.values,K=3,random_state=4)\n",
    "print(\"Time: {:.3f} hours\".format((time.time() - timestart)/3600))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_param4 = dict(                 \n",
    "                      \n",
    "    n_estimators=1000,                  # 树的个数--1000棵树建立xgboost\n",
    "    # silent = True,                    # 此为默认设置，不打印running boosting时的message。\n",
    "    objective='binary:logistic',        # 指定损失函数\n",
    "    # nthread = -1,（默认）              # 此为默认设置，并行线程数。\n",
    "    gamma=0,                            # （默认）设置节点划分要达到的loss减小量\n",
    "    min_child_weight = 1,               # （默认）叶子节点最小实例数据权重和\n",
    "    max_delta_step = 0,                 # （默认）此为默认设置，每棵树权重改变的最大步长。\n",
    "    colsample_btree=1,                  # （默认）训练每棵树时特征采样的比例\n",
    "    colsample_bylevel = 1,              # （默认）此为默认设置，树的每一级的每一次分裂时，对特征的采样比例。\n",
    "    reg_alpha = 0,                      # （默认此为默认设置，L1正则项系数。\n",
    "    reg_lambda = 1,                     # （默认）此为默认设置，L2正则项系数。\n",
    "    scale_pos_weight = scale_pos_weight_value,   # 设置正类别样本的权重。解决正反样本个数不平衡的问题。\n",
    "    base_score = 0.5,                   # （默认）此为默认设置，\n",
    "    seed = 1,                           # 随机数，因为涉及到随机采样等随机过程。\n",
    "    missing = np.nan,                   # XGB是能处理带缺失值的数据的模型，所以需要指出数据集中用什么代表缺失值。   \n",
    "    \n",
    "    learning_rate = 0.1,         # 这是调参得到的最佳参数，正好，也同时是默认值。\n",
    "    max_depth = 3,\n",
    "    subsample = 1.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 对训练集 X_tr_train, y_tr_train 进行训练，对 验证集 X_tr_test, y_tr_test 进行预测并计算 AUC 值。\n",
    "\n",
    "modelXGB2 = XGBClassifier(**XGB_param4)\n",
    "timestart = time.time()\n",
    "modelXGB2.fit(X_tr_train,y_tr_train,eval_set = [(X_tr_train,y_tr_train),(X_tr_test, y_tr_test)],\n",
    "              eval_metric =[\"logloss\",\"auc\"] ,early_stopping_rounds = 10,verbose = True)\n",
    "print(\"Time: {:.2f} seconds\".format(time.time() - timestart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelXGB2.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelXGB2.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.798225"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelXGB2.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_statistic(y_true,y_predicted_proba):\n",
    "    \n",
    "    fpr,tpr,thresholds = metrics.roc_curve(y_true,y_predicted_proba,pos_label=1)\n",
    "    return abs(tpr-fpr).max()\n",
    "\n",
    "\n",
    "def ks_curve(y_true,y_predicted_proba):\n",
    "    fpr,tpr,thresholds = metrics.roc_curve(y_true,y_predicted_proba,pos_label=1)\n",
    "    \n",
    "    font1 = {'family': 'Calibri','weight': 'normal','size': 18} # 轴标签字体\n",
    "    font2 = {'family': 'Calibri','weight': 'normal','size': 23} # 图标题字体\n",
    "    \n",
    "    fig = plt.figure(figsize = (6,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(thresholds,1.0-tpr,label=\"overdue\",color=\"navy\")\n",
    "    ax_t = ax.twinx()\n",
    "    ax_t.plot(thresholds,1.0-fpr,label=\"normal\",color=\"g\")\n",
    "    ax.plot(thresholds,tpr-fpr,label=\"K-S\",color=\"darkorange\")\n",
    "    ax.legend(loc=2)\n",
    "    ax_t.legend(loc=9)\n",
    "    ax_t.set_xlim(0.0, 1.0)\n",
    "    ax_t.set_ylim(0.0, 1.0)\n",
    "    ax.set_title('K-S curve',fontdict=font2 ) \n",
    "    ax.set_xlabel('threshold',fontdict=font1,labelpad= 2)  \n",
    "    ax.set_ylabel('True Positive Rate',fontdict=font1,labelpad= 6)\n",
    "    ax.set_ylabel('False Positive Rate',fontdict=font1,labelpad= 6)\n",
    "    ax.set_xlim(0.0, 1.0)\n",
    "    ax.set_ylim(0.0, 1.0)\n",
    "       \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ks_value2 is:  0.45967897552846243\n"
     ]
    }
   ],
   "source": [
    "y_predict_proba2 = modelXGB2.predict_proba(X_tr_test, ntree_limit=167)  # 注意设置 ntree_limit=167，使用最佳轮的集成树\n",
    "ks_value2 = ks_statistic(np.array(y_tr_test),y_predict_proba2[:,1])\n",
    "print(\"ks_value2 is: \",ks_value2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. 交叉验证  \n",
    "&ensp;&ensp;以上过程是建立在一次性二八分，用八份去通过GridSearchCV+hyperopt得到最佳超参数，然后在此超参数下对这八份进行学习得到最佳模型，然后用最佳模型对那二份进行预测并计算AUC和KS。  \n",
    "&ensp;&ensp;一次性二八分会否太单一？我认为可以在此超参数下使用交叉验证，多算几个验证分数。也就是把整个训练集X_tr, y_tr进行五折划分，在此超参数下学得5个模型，这5个模型对各自的验证集进行预测，得到5个auc和ks评分。可以看看这5个评分，算一下均分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold (n_splits=5,shuffle=True,random_state=9)  \n",
    "Xta = []\n",
    "Yta = []\n",
    "Xva = []\n",
    "Yva = []\n",
    "for train_index, validation_index in skf.split(X_tr.values,y_tr.values):  \n",
    "    Xta.append(X_tr.values[train_index])\n",
    "    Yta.append(y_tr.values[train_index])\n",
    "    Xva.append(X_tr.values[validation_index])\n",
    "    Yva.append(y_tr.values[validation_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestart = time.time()\n",
    "Scores2=[]\n",
    "Models2=[XGBClassifier(**XGB_param4) for i in range(len(Xta))]  # 创建 5 个模型\n",
    "for i in range(len(Xta)):\n",
    "    Models2[i].fit(Xta[i],Yta[i], eval_set = [(Xta[i],Yta[i]),( Xva[i],\n",
    "                                                               Yva[i])],\n",
    "                   eval_metric =[\"logloss\",\"auc\"] ,\n",
    "                   early_stopping_rounds = 10,verbose = True)\n",
    "    Scores2.append(Models2[i].best_score)\n",
    "    print(\"-------------------------------\")\n",
    "print(\"Time: {:.2f} seconds\".format(time.time() - timestart))\n",
    "print(\"Scores1 : \", Scores2)\n",
    "print(\"The mean auc is :\", np.mean(Scores2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "roundXGB2=[]  \n",
    "train_auc2=[]  \n",
    "validation_auc2=[]  \n",
    "best_iteration2=[]\n",
    "\n",
    "for i in range(len(Scores2)):\n",
    "    \n",
    "    roundXGB2.append(i+1)\n",
    "    \n",
    "    train_auc2.append(Models2[i].evals_result(\n",
    "    )[\"validation_0\"][\"auc\"][ Models2[i].best_iteration])\n",
    "    \n",
    "    validation_auc2.append(Models2[i].evals_result(\n",
    "    )[\"validation_1\"][\"auc\"][ Models2[i].best_iteration])\n",
    "    \n",
    "    best_iteration2.append(Models2[i].best_iteration)\n",
    "\n",
    "d = {\"model_round\":roundXGB2, \"train_auc\": train_auc2 ,\n",
    "     \"validation_auc\": validation_auc2 , \"best_iteration\": best_iteration2 }\n",
    "auc_result2 = pd.DataFrame(d,index=[1,2,3,4,5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 5. 训练最终XGB模型并预测未知样本集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练最终XGB模型并预测未知样本集\n",
    "\n",
    "modelXGB4 = XGBClassifier(**XGB_param4)  # XGB_param4是最佳超参数+固定参数\n",
    "modelXGB4.fit(X_tr, y_tr)\n",
    "proba_prediction4 = modelXGB4.predict_proba(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测结果整合成表\n",
    "\n",
    "XGBpre = pd.DataFrame(proba_prediction4[:,1],index=X_te.index,\n",
    "                      columns=[\"positive_proba\"]).reset_index()\n",
    "XGBpre.columns = [\"userid\",\"probability\"]  # 按官网提交示例修改列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBpre.to_csv(r'F:\\RiskPre2\\result\\XGBpre.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:\\\\RiskPre2\\\\result\\\\modelXGB5.pkl']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(modelXGB4, r'F:\\RiskPre2\\result\\modelXGB5.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "350px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
