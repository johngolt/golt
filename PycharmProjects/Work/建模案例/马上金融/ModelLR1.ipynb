{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说明：  \n",
    "本文件使用的是 Data clean 1 的数据整理结果（除了 target 列外，全部填充完毕，没有缺失值）。训练 LR 模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=5> Contents： </font>  \n",
    "1. XGBOOST特征重要性  \n",
    "2. Logistic Regression  \n",
    "&ensp;&ensp;&ensp;&ensp;2.1 特征标准化  \n",
    "&ensp;&ensp;&ensp;&ensp;2.2 计算经验相关系数矩阵  \n",
    "&ensp;&ensp;&ensp;&ensp;2.3 基于相关系数矩阵和XGB特征重要性的特征选择  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;2.3.1 先del_colinearity1 后 XGB特征重要性  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;2.3.2 del_colinearity2 内部融合XGB特征重要性  \n",
    "&ensp;&ensp;&ensp;&ensp;2.4 两种特征选择方式在LR模型上初步尝试  \n",
    "&ensp;&ensp;&ensp;&ensp;2.5 训练LR模型  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;2.5.1 准备数据集  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;2.5.2 GridSearchCV交叉验证粗取最佳超参数  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;2.5.3 对验证集进行预测并求得AUC---法1  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;2.5.4 对验证集进行预测并求得AUC---法2  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;2.5.5 查看并分析详细信息  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;2.5.6 hyperopt求取最佳超参数  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;2.5.7 交叉验证  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;2.5.8 训练最终LR模型并预测未知样本集  \n",
    "3. 提交结果  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy import special\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import covariance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials,rand\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "import time\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. XGBOOST 特征重要性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 将训练集二八分划分成训练集和验证集（shuffle+stratify），训练集和验证集同时给到XGB，训练出XGB模型。通过feature_importance得到所有特征的重要性，并用表格法和图示法展示。\n",
    "2. 用此模型小试一下，对验证集进行概率预测（关注排序而非真实的预测概率绝对值）。自定义 ks_statistic函数计算K-S统计量值为0.45， ks_curve函数画K-S图线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_tr_train is: (44304, 424)\n",
      "shape of y_tr_train is: (44304,)\n",
      "shape of X_tr_test is: (11077, 424)\n",
      "shape of y_tr_test is: (11077,)\n",
      "negative number/positive number in y_tr_train is: 6.7441006816990035\n",
      "negative number/positive number in y_tr_test is: 6.746153846153846\n"
     ]
    }
   ],
   "source": [
    "X_tr_train, X_tr_test, y_tr_train, y_tr_test = train_test_split(X_tr, y_tr,\n",
    "                    test_size = 0.2, shuffle=True, stratify=y_tr, \n",
    "                            random_state = 0)\n",
    "\n",
    "scale_pos_weight_value=len(y_tr_train[y_tr_train==0])/len(\n",
    "       y_tr_train[y_tr_train==1]) # XGB默认label==0是反类，label==1是正类。\n",
    "scale_pos_weight_value1=len(y_tr_test[y_tr_test==0])/len(\n",
    "           y_tr_test[y_tr_test==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.669162\tvalidation_0-auc:0.781234\tvalidation_1-logloss:0.670913\tvalidation_1-auc:0.743866\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-logloss:0.649867\tvalidation_0-auc:0.789589\tvalidation_1-logloss:0.652907\tvalidation_1-auc:0.758868\n",
      "[2]\tvalidation_0-logloss:0.633333\tvalidation_0-auc:0.794852\tvalidation_1-logloss:0.638207\tvalidation_1-auc:0.758414\n",
      "[3]\tvalidation_0-logloss:0.619523\tvalidation_0-auc:0.798146\tvalidation_1-logloss:0.625986\tvalidation_1-auc:0.759382\n",
      "[4]\tvalidation_0-logloss:0.60772\tvalidation_0-auc:0.80188\tvalidation_1-logloss:0.615571\tvalidation_1-auc:0.762851\n",
      "[5]\tvalidation_0-logloss:0.597535\tvalidation_0-auc:0.80507\tvalidation_1-logloss:0.60698\tvalidation_1-auc:0.764637\n",
      "[6]\tvalidation_0-logloss:0.587915\tvalidation_0-auc:0.811228\tvalidation_1-logloss:0.599076\tvalidation_1-auc:0.766086\n",
      "[7]\tvalidation_0-logloss:0.580161\tvalidation_0-auc:0.813316\tvalidation_1-logloss:0.592809\tvalidation_1-auc:0.767237\n",
      "[8]\tvalidation_0-logloss:0.573409\tvalidation_0-auc:0.81609\tvalidation_1-logloss:0.587494\tvalidation_1-auc:0.767653\n",
      "[9]\tvalidation_0-logloss:0.566874\tvalidation_0-auc:0.819765\tvalidation_1-logloss:0.582064\tvalidation_1-auc:0.76971\n",
      "[10]\tvalidation_0-logloss:0.561096\tvalidation_0-auc:0.822337\tvalidation_1-logloss:0.577329\tvalidation_1-auc:0.771635\n",
      "[11]\tvalidation_0-logloss:0.556287\tvalidation_0-auc:0.824414\tvalidation_1-logloss:0.573348\tvalidation_1-auc:0.773466\n",
      "[12]\tvalidation_0-logloss:0.551184\tvalidation_0-auc:0.826663\tvalidation_1-logloss:0.569743\tvalidation_1-auc:0.773429\n",
      "[13]\tvalidation_0-logloss:0.547073\tvalidation_0-auc:0.829426\tvalidation_1-logloss:0.566881\tvalidation_1-auc:0.773882\n",
      "[14]\tvalidation_0-logloss:0.54289\tvalidation_0-auc:0.831326\tvalidation_1-logloss:0.563785\tvalidation_1-auc:0.775168\n",
      "[15]\tvalidation_0-logloss:0.539036\tvalidation_0-auc:0.833821\tvalidation_1-logloss:0.561514\tvalidation_1-auc:0.775418\n",
      "[16]\tvalidation_0-logloss:0.536008\tvalidation_0-auc:0.835559\tvalidation_1-logloss:0.559607\tvalidation_1-auc:0.775374\n",
      "[17]\tvalidation_0-logloss:0.532764\tvalidation_0-auc:0.837229\tvalidation_1-logloss:0.557263\tvalidation_1-auc:0.776563\n",
      "[18]\tvalidation_0-logloss:0.529181\tvalidation_0-auc:0.840749\tvalidation_1-logloss:0.554906\tvalidation_1-auc:0.776573\n",
      "[19]\tvalidation_0-logloss:0.526342\tvalidation_0-auc:0.842759\tvalidation_1-logloss:0.553116\tvalidation_1-auc:0.77643\n",
      "[20]\tvalidation_0-logloss:0.523663\tvalidation_0-auc:0.845116\tvalidation_1-logloss:0.551326\tvalidation_1-auc:0.777144\n",
      "[21]\tvalidation_0-logloss:0.520911\tvalidation_0-auc:0.846918\tvalidation_1-logloss:0.549733\tvalidation_1-auc:0.776592\n",
      "[22]\tvalidation_0-logloss:0.518289\tvalidation_0-auc:0.84898\tvalidation_1-logloss:0.548023\tvalidation_1-auc:0.777101\n",
      "[23]\tvalidation_0-logloss:0.515393\tvalidation_0-auc:0.850969\tvalidation_1-logloss:0.546293\tvalidation_1-auc:0.777149\n",
      "[24]\tvalidation_0-logloss:0.512394\tvalidation_0-auc:0.853773\tvalidation_1-logloss:0.544444\tvalidation_1-auc:0.777748\n",
      "[25]\tvalidation_0-logloss:0.509484\tvalidation_0-auc:0.856118\tvalidation_1-logloss:0.542551\tvalidation_1-auc:0.778009\n",
      "[26]\tvalidation_0-logloss:0.506408\tvalidation_0-auc:0.858245\tvalidation_1-logloss:0.540649\tvalidation_1-auc:0.77866\n",
      "[27]\tvalidation_0-logloss:0.50411\tvalidation_0-auc:0.859586\tvalidation_1-logloss:0.539146\tvalidation_1-auc:0.779113\n",
      "[28]\tvalidation_0-logloss:0.50149\tvalidation_0-auc:0.86182\tvalidation_1-logloss:0.537457\tvalidation_1-auc:0.779905\n",
      "[29]\tvalidation_0-logloss:0.498849\tvalidation_0-auc:0.863197\tvalidation_1-logloss:0.535483\tvalidation_1-auc:0.780873\n",
      "[30]\tvalidation_0-logloss:0.496718\tvalidation_0-auc:0.864749\tvalidation_1-logloss:0.534056\tvalidation_1-auc:0.781193\n",
      "[31]\tvalidation_0-logloss:0.494103\tvalidation_0-auc:0.866873\tvalidation_1-logloss:0.532754\tvalidation_1-auc:0.781177\n",
      "[32]\tvalidation_0-logloss:0.491471\tvalidation_0-auc:0.868221\tvalidation_1-logloss:0.531023\tvalidation_1-auc:0.782396\n",
      "[33]\tvalidation_0-logloss:0.48895\tvalidation_0-auc:0.870008\tvalidation_1-logloss:0.529599\tvalidation_1-auc:0.782965\n",
      "[34]\tvalidation_0-logloss:0.486507\tvalidation_0-auc:0.871232\tvalidation_1-logloss:0.52783\tvalidation_1-auc:0.784185\n",
      "[35]\tvalidation_0-logloss:0.484517\tvalidation_0-auc:0.872779\tvalidation_1-logloss:0.5266\tvalidation_1-auc:0.784379\n",
      "[36]\tvalidation_0-logloss:0.48287\tvalidation_0-auc:0.874049\tvalidation_1-logloss:0.525759\tvalidation_1-auc:0.78413\n",
      "[37]\tvalidation_0-logloss:0.480459\tvalidation_0-auc:0.875838\tvalidation_1-logloss:0.524386\tvalidation_1-auc:0.784533\n",
      "[38]\tvalidation_0-logloss:0.477855\tvalidation_0-auc:0.877578\tvalidation_1-logloss:0.522551\tvalidation_1-auc:0.785111\n",
      "[39]\tvalidation_0-logloss:0.475767\tvalidation_0-auc:0.878849\tvalidation_1-logloss:0.521032\tvalidation_1-auc:0.786396\n",
      "[40]\tvalidation_0-logloss:0.473358\tvalidation_0-auc:0.880773\tvalidation_1-logloss:0.519827\tvalidation_1-auc:0.786236\n",
      "[41]\tvalidation_0-logloss:0.470535\tvalidation_0-auc:0.88331\tvalidation_1-logloss:0.518155\tvalidation_1-auc:0.786291\n",
      "[42]\tvalidation_0-logloss:0.46767\tvalidation_0-auc:0.885561\tvalidation_1-logloss:0.516665\tvalidation_1-auc:0.786528\n",
      "[43]\tvalidation_0-logloss:0.466593\tvalidation_0-auc:0.886254\tvalidation_1-logloss:0.515997\tvalidation_1-auc:0.78652\n",
      "[44]\tvalidation_0-logloss:0.465362\tvalidation_0-auc:0.886995\tvalidation_1-logloss:0.515305\tvalidation_1-auc:0.786517\n",
      "[45]\tvalidation_0-logloss:0.464374\tvalidation_0-auc:0.887776\tvalidation_1-logloss:0.514745\tvalidation_1-auc:0.78656\n",
      "[46]\tvalidation_0-logloss:0.462111\tvalidation_0-auc:0.889556\tvalidation_1-logloss:0.513528\tvalidation_1-auc:0.786979\n",
      "[47]\tvalidation_0-logloss:0.460992\tvalidation_0-auc:0.89019\tvalidation_1-logloss:0.513095\tvalidation_1-auc:0.78679\n",
      "[48]\tvalidation_0-logloss:0.45867\tvalidation_0-auc:0.891821\tvalidation_1-logloss:0.511611\tvalidation_1-auc:0.787102\n",
      "[49]\tvalidation_0-logloss:0.457817\tvalidation_0-auc:0.89242\tvalidation_1-logloss:0.511188\tvalidation_1-auc:0.786932\n",
      "[50]\tvalidation_0-logloss:0.456634\tvalidation_0-auc:0.893248\tvalidation_1-logloss:0.510601\tvalidation_1-auc:0.786786\n",
      "[51]\tvalidation_0-logloss:0.455355\tvalidation_0-auc:0.894107\tvalidation_1-logloss:0.509786\tvalidation_1-auc:0.787053\n",
      "[52]\tvalidation_0-logloss:0.4531\tvalidation_0-auc:0.895972\tvalidation_1-logloss:0.508495\tvalidation_1-auc:0.787196\n",
      "[53]\tvalidation_0-logloss:0.451681\tvalidation_0-auc:0.896891\tvalidation_1-logloss:0.507847\tvalidation_1-auc:0.786845\n",
      "[54]\tvalidation_0-logloss:0.449941\tvalidation_0-auc:0.897811\tvalidation_1-logloss:0.506686\tvalidation_1-auc:0.787289\n",
      "[55]\tvalidation_0-logloss:0.448041\tvalidation_0-auc:0.89932\tvalidation_1-logloss:0.505735\tvalidation_1-auc:0.787288\n",
      "[56]\tvalidation_0-logloss:0.447559\tvalidation_0-auc:0.899598\tvalidation_1-logloss:0.505552\tvalidation_1-auc:0.787174\n",
      "[57]\tvalidation_0-logloss:0.446068\tvalidation_0-auc:0.90053\tvalidation_1-logloss:0.504727\tvalidation_1-auc:0.786936\n",
      "[58]\tvalidation_0-logloss:0.445331\tvalidation_0-auc:0.901011\tvalidation_1-logloss:0.504323\tvalidation_1-auc:0.786778\n",
      "[59]\tvalidation_0-logloss:0.443209\tvalidation_0-auc:0.902464\tvalidation_1-logloss:0.503276\tvalidation_1-auc:0.787004\n",
      "[60]\tvalidation_0-logloss:0.44177\tvalidation_0-auc:0.903345\tvalidation_1-logloss:0.502383\tvalidation_1-auc:0.787388\n",
      "[61]\tvalidation_0-logloss:0.440271\tvalidation_0-auc:0.90444\tvalidation_1-logloss:0.501522\tvalidation_1-auc:0.787387\n",
      "[62]\tvalidation_0-logloss:0.43844\tvalidation_0-auc:0.905732\tvalidation_1-logloss:0.500588\tvalidation_1-auc:0.787411\n",
      "[63]\tvalidation_0-logloss:0.436889\tvalidation_0-auc:0.906754\tvalidation_1-logloss:0.499824\tvalidation_1-auc:0.787272\n",
      "[64]\tvalidation_0-logloss:0.436116\tvalidation_0-auc:0.907339\tvalidation_1-logloss:0.499513\tvalidation_1-auc:0.787201\n",
      "[65]\tvalidation_0-logloss:0.435398\tvalidation_0-auc:0.907792\tvalidation_1-logloss:0.499296\tvalidation_1-auc:0.786901\n",
      "[66]\tvalidation_0-logloss:0.434789\tvalidation_0-auc:0.908163\tvalidation_1-logloss:0.499013\tvalidation_1-auc:0.786816\n",
      "[67]\tvalidation_0-logloss:0.432852\tvalidation_0-auc:0.909514\tvalidation_1-logloss:0.497944\tvalidation_1-auc:0.786867\n",
      "[68]\tvalidation_0-logloss:0.431223\tvalidation_0-auc:0.910645\tvalidation_1-logloss:0.497259\tvalidation_1-auc:0.786504\n",
      "[69]\tvalidation_0-logloss:0.4293\tvalidation_0-auc:0.911788\tvalidation_1-logloss:0.495839\tvalidation_1-auc:0.787118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalidation_0-logloss:0.42749\tvalidation_0-auc:0.91319\tvalidation_1-logloss:0.495111\tvalidation_1-auc:0.787057\n",
      "[71]\tvalidation_0-logloss:0.426462\tvalidation_0-auc:0.913775\tvalidation_1-logloss:0.494496\tvalidation_1-auc:0.787303\n",
      "[72]\tvalidation_0-logloss:0.425339\tvalidation_0-auc:0.914567\tvalidation_1-logloss:0.493858\tvalidation_1-auc:0.787172\n",
      "Stopping. Best iteration:\n",
      "[62]\tvalidation_0-logloss:0.43844\tvalidation_0-auc:0.905732\tvalidation_1-logloss:0.500588\tvalidation_1-auc:0.787411\n",
      "\n",
      "Time: 171.69 seconds\n"
     ]
    }
   ],
   "source": [
    "modelXGB1 = XGBClassifier(\n",
    "    max_depth=6,    \n",
    "    n_estimators=1000,                  \n",
    "    objective='binary:logistic',        \n",
    "    scale_pos_weight = scale_pos_weight_value,  \n",
    "    seed = 1,                           \n",
    "    missing = np.nan)\n",
    "\n",
    "timestart = time.time()\n",
    "modelXGB1.fit(X_tr_train,y_tr_train,\n",
    "        eval_set = [(X_tr_train,y_tr_train),(X_tr_test, y_tr_test)],\n",
    "       eval_metric =[\"logloss\",\"auc\"] ,early_stopping_rounds = 10,\n",
    "              verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenames = X_tr_train.columns\n",
    "FeatureImportance = pd.DataFrame(data = modelXGB1.feature_importances_, \n",
    "                    index = featurenames, columns = ['feature importance'])\n",
    "FeatureImportance = FeatureImportance.sort_values(\n",
    "    by = ['feature importance'], ascending=False)\n",
    "\n",
    "fig1 = plt.figure(figsize = (8,16))\n",
    "ax1 = fig1.add_subplot(111)\n",
    "plot_importance(modelXGB1, ax1, height=0.8, xlim=None, ylim=None, \n",
    "                        title='Feature importance', xlabel='F score', \n",
    "                       ylabel='Features',importance_type='weight', \n",
    "                grid=True,max_num_features=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&ensp;&ensp;赛题选择的这个K-S统计量，只与被预测样本的排序有关，而与真正的逾期概率值本身的绝对大小无关。get到这点很重要。所以在训练模型的时候，我们关注的就仅仅是预测的排序，而非预测为违约的实际概率值。这种情况，用AUC作为评价函数就比较好，此指标只与排序有关，与预测的概率值的绝对大小无关。而且，这种情况下，若总体样本不平衡，则可以使用 scale_pos_weight或class_weight参数调整类别不平衡。（调整这样的参数会影响到 预测的概率值的绝对大小，但对提高预测排序的准确性有帮助）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_statistic(y_true,y_predicted_proba):\n",
    "    \n",
    "    fpr,tpr,thresholds = metrics.roc_curve(y_true,y_predicted_proba,\n",
    "                                           pos_label=1)\n",
    "    return abs(tpr-fpr).max()\n",
    "\n",
    "\n",
    "def ks_curve(y_true,y_predicted_proba):\n",
    "    fpr,tpr,thresholds = metrics.roc_curve(y_true,y_predicted_proba,\n",
    "                                           pos_label=1)\n",
    "    \n",
    "    font1 = {'family': 'Calibri','weight': 'normal','size': 18} \n",
    "    font2 = {'family': 'Calibri','weight': 'normal','size': 23} \n",
    "    \n",
    "    fig = plt.figure(figsize = (6,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(thresholds,1.0-tpr,label=\"overdue\",color=\"navy\")\n",
    "    ax_t = ax.twinx()\n",
    "    ax_t.plot(thresholds,1.0-fpr,label=\"normal\",color=\"g\")\n",
    "    ax.plot(thresholds,tpr-fpr,label=\"K-S\",color=\"darkorange\")\n",
    "    ax.legend(loc=2)\n",
    "    ax_t.legend(loc=9)\n",
    "    ax_t.set_xlim(0.0, 1.0)\n",
    "    ax_t.set_ylim(0.0, 1.0)\n",
    "    ax.set_title('K-S curve',fontdict=font2 ) \n",
    "    ax.set_xlabel('threshold',fontdict=font1,labelpad= 2)  \n",
    "    ax.set_ylabel('True Positive Rate',fontdict=font1,labelpad= 6)\n",
    "    ax.set_ylabel('False Positive Rate',fontdict=font1,labelpad= 6)\n",
    "    ax.set_xlim(0.0, 1.0)\n",
    "    ax.set_ylim(0.0, 1.0)\n",
    "       \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ks_value1 is:  0.4478387063335752\n"
     ]
    }
   ],
   "source": [
    "y_predict_proba1 = modelXGB1.predict_proba(X_tr_test, ntree_limit=58)\n",
    "ks_value1 = ks_statistic(np.array(y_tr_test),y_predict_proba1[:,1])\n",
    "print(\"ks_value1 is: \",ks_value1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 对训练集中的所有特征进行标准化（包括onehot encoder得到的特征 和 连续型数值特征），记录每个特征的均值方差，将其应用到未知样本集，对它们进行标准化。\n",
    "2. 对训练集的所有特征计算相关系数矩阵。\n",
    "3. 找出相关系数>0.7的变量，只保留其中之一，结合XGB的特征重要性，完成特征筛选。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 计算经验相关系数矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_tr_correlation_matrix is: (424, 424)\n"
     ]
    }
   ],
   "source": [
    "X_tr_correlation_matrix = covariance.empirical_covariance(X_tr_standard)\n",
    "print(\"shape of X_tr_correlation_matrix is:\",X_tr_correlation_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 2.3.1 先 del_colinearity1 后 XGB特征重要性    \n",
    "\n",
    "&ensp;&ensp;先删除一部分特征，使得剩下的特征两两之间的相关系数<0.8.然后，再从剩下的特征中删除在XGB特征重要性排序中处于后10% 的特征，最后剩下的特征，是用于训练LR模型的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colinearity(correlation_matrix):\n",
    "    num=correlation_matrix.shape[0] # num是相关矩阵的行数\n",
    "    L=[]\n",
    "    for i in range(num-1):  # 只需要检查不含主对角线的上三角形。\n",
    "        for j in range(i+1,num):\n",
    "            if correlation_matrix[i,j]>0.8:\n",
    "                L.append([i,j]) # 把相关系数大于0.8的特征对添加到 L中。L是二维列表。\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "869\n"
     ]
    }
   ],
   "source": [
    "L = colinearity(X_tr_correlation_matrix)\n",
    "print(len(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's 89676 variancepair.\n"
     ]
    }
   ],
   "source": [
    "# 424 个字段变量，一共有 89676 对。\n",
    "\n",
    "variancepair = special.comb(424,2)  \n",
    "# scipy计算排列组合（从424个字段中挑选两个组成一对，总的方法数为 89676）。\n",
    "print(\"There's %d variancepair.\" % variancepair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "colinearity_counts = pd.value_counts(np.array(L).flatten())\n",
    "colinearity_counts = pd.DataFrame(colinearity_counts).reset_index()\n",
    "colinearity_counts.columns = [\"colindex\",\"colinearity_counts\"]  # 改列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 869 pairs of features have correlation coefficient more than 0.8.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0     3     8\n",
       "1     3    13\n",
       "2     3    19\n",
       "3     8    13"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colinearity_pairs = pd.DataFrame(L,columns=[\"col1\",\"col2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "参数 colinearity_pairs 是一个dataframe，它记录了当前 424 个特征中，\n",
    "所有的 相关系数>0.8的特征对。\n",
    "# 此表有两列，都是特征索引，此dataframe的每一行代表一个特征对，\n",
    "它们之间的相关系数>0.8.此 dataframe里的特征对是无重复的。\n",
    "# 首先，由 colinearity_pairs计算其中每个特征出现的次数，并排序，\n",
    "得到 colinearity_counts这个dataframe，里面有两列，\n",
    "# 左列 colindex 是特征的索引值，右列 colinearity_counts \n",
    "是它在colinearity_pairs里出现的次数，也就是说，\n",
    "# 这个特征与多少个其它特征强相关。并按照这个次数由大到小排序。\n",
    "\n",
    "# 然后，思路是这样的，若有一对特征对强相关，则把其中之一删掉即可，\n",
    "另一个可以保留。而非两个全删。而我现在需要做的就是，把\n",
    "# colinearity_counts里的colindex列里的特征择性删除一部分，\n",
    "使得剩下的变量之间不再强相关，而且这时， colinearity_pairs会变空，\n",
    "# 也就是剩下的变量里不再有强相关的特征对。并用 D 列表记录下了需要删掉的特征的索引。\n",
    "# 所以，我根据 colinearity_counts 的排序，\n",
    "先把排在首位的特征提取出来，把\n",
    "# colinearity_pairs 里 所有含此特征的特征对全部删掉，然后把此特征记录在D里，\n",
    "然后检查 colinearity_pairs 看是否为空，如果\n",
    "# 不是空，则继续选择 colinearity_counts里的特征，\n",
    "把colinearity_pairs 里 所有含此特征的特征对全部删掉，然后把此特征记录在D里，\n",
    "# 然后检查 colinearity_pairs 看是否为空，若为空，则跳出循环，返回 D。\n",
    "# 缺点：本函数还是具有一定盲目性的，因为colinearity_counts排序中，\n",
    "很多变量是相同次数的，但就是依据 colinearity_counts的排序\n",
    "# 取逐个尝试了。其实我觉得如果改进的话，可以看看相同次数的特征，\n",
    "它们和其它特征的相关性，虽然都不到0.8，但是还是可能会有不同，\n",
    "# 尽量删除和其它变量相关性较强的。\n",
    "# 这里我选择的删除顺序是按照 与其它变量存在强相关的次数，按照此次数排序，逐个删除的。\n",
    "我认为还有一种思路，就是使用 XGB得到的特征\n",
    "# 重要性，从最不重要的特征开始尝试，逐个删除，使得留下来的是重要的特征，\n",
    "也就是 del_colinearity2 函数。\n",
    "\n",
    "def del_colinearity1(colinearity_pairs):\n",
    "    \n",
    "    colinearity_counts = pd.value_counts(\n",
    "        np.array(colinearity_pairs).flatten())\n",
    "    colinearity_counts = pd.DataFrame(colinearity_counts).reset_index()\n",
    "    colinearity_counts.columns = [\"colindex\",\"colinearity_counts\"] \n",
    "    \n",
    "    c = colinearity_pairs.columns\n",
    "    D=[]\n",
    "    \n",
    "    for i in colinearity_counts[\"colindex\"]:\n",
    "        print(\"use %d to delete\" % i)\n",
    "        n0 = len(colinearity_pairs)\n",
    "        print(\"before delete,the pair number is:\",n0)\n",
    "        \n",
    "        colinearity_pairs = colinearity_pairs[\n",
    "            (~colinearity_pairs[c[0]].isin([i]))&(\n",
    "                ~colinearity_pairs[c[1]].isin([i]))]\n",
    "        \n",
    "        n1 = len(colinearity_pairs)\n",
    "        print(\"after delete, the pair number is:\",n1)\n",
    "        \n",
    "        if n1<n0:                     \n",
    "            print(\"append %d to D\" % i) \n",
    "            D.append(i)\n",
    "        \n",
    "        if len(colinearity_pairs)==0:\n",
    "            print(\"now colinearity_pairs is null,break\")\n",
    "            break\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del_features1 = del_colinearity1(colinearity_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C = [i for i in range(len(data_column_names))]\n",
    "choose = list( set(C)-set(del_features1) )\n",
    "tmp1 = pd.DataFrame(data_column_names)\n",
    "data_column_names_delcolinear1 = tmp1.iloc[choose]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "featureimportance = pd.DataFrame(modelXGB1.feature_importances_)\n",
    "featureimportance = featureimportance.reset_index() \n",
    "featureimportance.columns=[\"featureindex\",\"featureimportance\"]\n",
    "featureimportance.sort_values(by=\"featureimportance\",ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>featureindex</th>\n",
       "      <th>featureimportance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>421</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>162</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     featureindex  featureimportance\n",
       "421           421                0.0\n",
       "45             45                0.0\n",
       "162           162                0.0\n",
       "25             25                0.0\n",
       "27             27                0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureimportance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features without colinear&most important is: 154\n"
     ]
    }
   ],
   "source": [
    "tmp3 = np.array(data_column_names_delcolinear1.index) \n",
    "tmp4 = np.array(featureimportance[\n",
    "    \"featureindex\"][0:int(len(featureimportance)*0.1)]) \n",
    "\n",
    "data_column_names_delcolinear1_1 = np.setdiff1d(tmp3,tmp4)\n",
    "tmp5 = pd.DataFrame(data_column_names)\n",
    "data_column_names_delcolinear1_1 = tmp5.iloc[\n",
    "    data_column_names_delcolinear1_1]\n",
    "data_column_names_delcolinear1_1.columns = [\"featurename\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 del_colinearity2内部融合XGB特征重要性  \n",
    "  \n",
    "&ensp;&ensp;根据XGB得到的特征重要性，由小到大，逐个删除，每次删除后都检查剩下的特征还有无相关系数>0.8的特征对，直到剩下的所有特征两两之间的相关系数都<=0.8，这些特征就是训练LR模型需要的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def del_colinearity2(colinearity_pairs,XGB_feature_importance):\n",
    "    \n",
    "    c = colinearity_pairs.columns\n",
    "    D=[]  # 记录需要删除的特征的索引。\n",
    "    \n",
    "    for i in XGB_feature_importance[\"featureindex\"]:\n",
    "        print(\"use %d to delete\" % i)\n",
    "        n0 = len(colinearity_pairs)\n",
    "        print(\"before delete,the pair number is:\",n0)\n",
    "        \n",
    "        colinearity_pairs = colinearity_pairs[\n",
    "            (~colinearity_pairs[c[0]].isin([i]))&(\n",
    "                ~colinearity_pairs[c[1]].isin([i]))]\n",
    "        n1 = len(colinearity_pairs)\n",
    "        print(\"after delete, the pair number is:\",n1)\n",
    "        \n",
    "        if n1<n0:                   \n",
    "            print(\"append %d to D\" % i) \n",
    "            D.append(i)     \n",
    "            \n",
    "        \n",
    "        print(\"-----------------------\")\n",
    "        \n",
    "        if len(colinearity_pairs)==0:\n",
    "            print(\"now colinearity_pairs is null,break\")\n",
    "            break\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_features2 = del_colinearity2(colinearity_pairs,featureimportance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = [i for i in range(len(data_column_names))]\n",
    "choose = list( set(C)-set(del_features2) )\n",
    "tmp2 = pd.DataFrame(data_column_names)\n",
    "data_column_names_delcolinear2 = tmp2.iloc[choose]\n",
    "data_column_names_delcolinear2.columns = [\"featurename\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 两种特征选择方式在 LR模型上初步尝试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&ensp;&ensp;XGBOOST算特征重要性时曾将训练集data_tr的字段变量部分X_tr和目标变量部分y_tr，三七分成训练集X_tr_train, y_tr_train,和验证集 X_tr_test, y_tr_test。这里沿用此划分。然后，将训练集X_tr_train标准化得X_tr_train_std，将得到的均值方差用来标准化验证集X_tr_test，得到X_tr_test_std。（注意，不能沿用之前计算相关系数矩阵时得到的标准化数据，因为那个是将整个训练集进行标准化，如果这样再划分训练集验证集的话，两者就是相关的，这样做是不对的。应该把训练集的标准用到验证集上。）然后，分别用 2.3.1 选择得到的特征、2.3.2选择得到的特征 在 训练集上试，在验证集上测试结果。评分以 AUC指标为准。粗略评价2.3.1 、2.3.2哪种特征选择结果更好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 标准化 训练集的字段变量部分 X_tr_train 为 X_tr_train_standard。\n",
    "# 用训练集的均值和方差标准化 验证集的字段变量部分 X_tr_test 为 X_tr_test_standard。\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(X_tr_train)\n",
    "X_tr_train_standard = scaler2.transform(X_tr_train)\n",
    "X_tr_test_standard = scaler2.transform(X_tr_test)\n",
    "print(\"shape of X_tr_train_standard is: \",X_tr_train_standard.shape)\n",
    "print(\"shape of X_tr_test_standard is: \",X_tr_test_standard.shape)\n",
    "\n",
    "\n",
    "# 将标准化的训练集 X_tr_train_standard 转化为 dataframe并命名为 X_tr_train_std 。\n",
    "# 将标准化的验证集 X_tr_test_standard 转化为 dataframe并命名为 X_tr_test_std 。\n",
    "\n",
    "X_tr_train_std = pd.DataFrame(X_tr_train_standard,columns=data_column_names)\n",
    "X_tr_test_std = pd.DataFrame(X_tr_test_standard,columns=data_column_names)\n",
    "print(\"shape of X_tr_train_std is: \",X_tr_train_std.shape)\n",
    "print(\"shape of X_tr_test_std is: \",X_tr_test_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_tr_train_std_choose1 is: (44304, 154)\n",
      "shape of y_tr_train is: (44304,)\n",
      "shape of X_tr_test_std_choose1 is: (11077, 154)\n",
      "shape of y_tr_test is: (11077,)\n"
     ]
    }
   ],
   "source": [
    "# 这里，对训练集和验证集的X部分使用 2.3.1的特征选择法data_column_names_delcolinear1_1进行特征选择。\n",
    "# 得到 X_tr_train_std_choose1可用于训练，X_tr_test_std_choose1可用于验证。它们都只包含 152 个特征。\n",
    "\n",
    "X_tr_train_std_choose1 = X_tr_train_std.loc[:,\n",
    "                        data_column_names_delcolinear1_1[\"featurename\"]]\n",
    "X_tr_test_std_choose1 = X_tr_test_std.loc[:,\n",
    "                    data_column_names_delcolinear1_1[\"featurename\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_tr_train_std_choose2 is: (44304, 155)\n",
      "shape of y_tr_train is: (44304,)\n",
      "shape of X_tr_test_std_choose2 is: (11077, 155)\n",
      "shape of y_tr_test is: (11077,)\n"
     ]
    }
   ],
   "source": [
    "# 这里，对训练集和验证集的X部分使用 2.3.2的特征选择法data_column_names_delcolinear2进行特征选择。\n",
    "# 得到 X_tr_train_std_choose2可用于训练，X_tr_test_std_choose2可用于验证。它们都只包含 159 个特征。\n",
    "\n",
    "X_tr_train_std_choose2 = X_tr_train_std.loc[:,\n",
    "                            data_column_names_delcolinear2[\"featurename\"]]\n",
    "X_tr_test_std_choose2 = X_tr_test_std.loc[:,\n",
    "                            data_column_names_delcolinear2[\"featurename\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={'C':1}     \n",
    "LR_parameter = {\"penalty\": \"l2\",\"tol\": 1e-4,\"class_weight\": 'balanced', \n",
    "                'solver': 'liblinear','max_iter':1000,'random_state':1}  \n",
    "LR_parameter.update(args)\n",
    "\n",
    "\n",
    "modelLR1 = LogisticRegression(**LR_parameter)\n",
    "modelLR1.fit(X_tr_train_std_choose1, y_tr_train)\n",
    "proba_prediction1 = modelLR1.predict_proba(X_tr_test_std_choose1)\n",
    "\n",
    "\n",
    "modelLR2 = LogisticRegression(**LR_parameter)\n",
    "modelLR2.fit(X_tr_train_std_choose2, y_tr_train)\n",
    "proba_prediction2 = modelLR2.predict_proba(X_tr_test_std_choose2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp6 = pd.DataFrame(y_tr_test,columns=[\"target\"]\n",
    "                   ).reset_index().drop(\"userID\",axis=1)\n",
    "proba_prediction1 = pd.DataFrame(proba_prediction1,\n",
    "                                 columns=[\"class0\",\"class1\"])\n",
    "proba_prediction_1 = pd.concat([proba_prediction1,tmp6],axis=1)\n",
    "proba_prediction2 = pd.DataFrame(proba_prediction2, \n",
    "                                 columns=[\"class0\",\"class1\"])\n",
    "proba_prediction_2 = pd.concat([proba_prediction2,tmp6],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc1 is  0.6572063781558961\n",
      "auc2 is  0.6587271234000788\n"
     ]
    }
   ],
   "source": [
    "fpr1,tpr1,thresholds1 = metrics.roc_curve(proba_prediction_1[\"target\"], \n",
    "                                          proba_prediction_1[\"class1\"],\n",
    "                                          pos_label=1)\n",
    "fpr2,tpr2,thresholds2 = metrics.roc_curve(proba_prediction_2[\"target\"], \n",
    "                                          proba_prediction_2[\"class1\"],\n",
    "                                          pos_label=1)\n",
    "\n",
    "auc1 = metrics.auc (fpr1,tpr1)\n",
    "auc2 = metrics.auc (fpr2,tpr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xecbade3320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "font1 = {'family': 'Calibri','weight': 'normal','size': 18} # 轴标签字体\n",
    "font2 = {'family': 'Calibri','weight': 'normal','size': 23} # 图标题字体\n",
    "\n",
    "fig3 = plt.figure(figsize = (16,6))\n",
    "lw = 2\n",
    "ax1 = fig3.add_subplot(121)\n",
    "ax1.plot(fpr1,tpr1,color=\"darkorange\",lw=2, label=\"ROC curve 1\")\n",
    "ax1.plot([0,1],[0,1],color=\"navy\",lw=lw, linestyle=\"--\")\n",
    "ax1.set_xlim(0.0, 1.0)\n",
    "ax1.set_ylim(0.0, 1.0)\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC curve 1',fontdict=font2)\n",
    "ax1.legend(loc=\"lower right\")\n",
    "\n",
    "ax2 = fig3.add_subplot(122)\n",
    "ax2.plot(fpr2,tpr2,color=\"darkorange\",lw=2, label=\"ROC curve 2\")\n",
    "ax2.plot([0,1],[0,1],color=\"navy\",lw=lw, linestyle=\"--\")\n",
    "ax2.set_xlim(0.0, 1.0)\n",
    "ax2.set_ylim(0.0, 1.0)\n",
    "ax2.set_xlabel('False Positive Rate')\n",
    "ax2.set_ylabel('True Positive Rate')\n",
    "ax2.set_title('ROC curve 2',fontdict=font2)\n",
    "ax2.legend(loc=\"lower right\")\n",
    "\n",
    "plt.subplots_adjust(wspace = 0.5, hspace =0.5)  # 调整每个子图之间的距离    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：   \n",
    "1. 阈值为 0.8时，auc1 = 0.6477, auc2 = 0.6519，提示用2.3.2得到的特征训练LR模型略好于用2.3.1得到的特征。\n",
    "2. 经试验发现，如果以上步骤不变，仅调节 colinearity 中的阈值，也就是相关系数大于多少的特征对要删去其一，会发现，  \n",
    "阈值为 0.6时，auc1 = 0.6324, auc2 = 0.6447  \n",
    "阈值为 0.7时，auc1 = 0.6398, auc2 = 0.6468  \n",
    "阈值为 0.8时，auc1 = 0.6477, auc2 = 0.6519  \n",
    "阈值为 0.9时，auc1 = 0.6556, auc2 = 0.6552  \n",
    "阈值为 1.0时，auc1 = 0.6586, auc2 = 0.6583  \n",
    "这似乎提示，不删除强相关的特征，即保留所有特征会更好？  \n",
    "3. 改变 LR 的超参数C并不会引起 AUC值改变太多。（相关系数阈值0.8）   \n",
    "C为  1 时，auc1 = 0.647744 , acu2 = 0.651925  \n",
    "C为 10 时，auc1 = 0.647729 , acu2 = 0.651930  \n",
    "C为100 时，auc1 = 0.647727 , acu2 = 0.651935   \n",
    "所以并没有特别大的改观。  \n",
    "4. 试过增大LR模型的max_iter，发现基本没有变化。（阈值0.8，C为1）   \n",
    "max_iter为  100 时，auc1 = 0.647744 , acu2 = 0.651925\n",
    "max_iter为 1000 时，auc1 = 0.647744 , acu2 = 0.651925\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 训练 LR 模型  \n",
    "\n",
    "1. 沿用计算XGBOOST特征重要性时得到的数据集：将训练集data_tr进行train_test_split二八分（此函数里面有shuffle和stratify选项），得到字段部分和目标变量部分分类得X_tr_train, X_tr_test, y_tr_train, y_tr_test。然后，因为2.4中显示特征选择会降低AUC，所以此处不进行特征选择，而是使用所有特征进行训练。训练集X_tr_train，y_tr_train。验证集X_tr_test，y_tr_test。\n",
    "2. LR模型只有一个超参数C。使用 pipeline，将 “标准化StandardScaler”和“LR模型”组成管道。通过GridSearchCV进行对LR的超参数C进行交叉验证，粗选出最佳C。\n",
    "3. 在最佳C下，LR模型对完整数据集X_tr_train，y_tr_train进行fit，得到最佳模型，然后对验证集X_tr_test，y_tr_test进行预测，并计算auc和ks评分。\n",
    "4. 围绕粗选出的最佳C设置一个小范围，使用 hyperopt 进行精细的选择。得到最佳C。\n",
    "5. 将完整训练集进行五折交叉验证（在最佳C下），得到5个 auc和ks值供参考。\n",
    "6. 在最佳C下，对完整训练集X_tr,y_tr训练LR模型，得到的模型对未知样本集 X_te进行预测，保存预测结果 LRPre. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 准备数据集。\n",
    "&ensp;&ensp;沿用计算XGBOOST特征重要性时得到的数据集：将训练集data_tr进行train_test_split二八分（此函数里面有shuffle和stratify选项），得到字段部分和目标变量部分分类得X_tr_train, X_tr_test, y_tr_train, y_tr_test。然后，因为2.4中显示特征选择会降低AUC，所以此处不进行特征选择，而是使用所有特征进行训练。 训练集X_tr_train，y_tr_train可用于之后的交叉验证求最佳超参数。验证集X_tr_test，y_tr_test可用于得到最佳超参数并训练出最佳模型后，用此模型对验证集进行预测，计算auc。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2 GridSearchCV 交叉验证粗取最佳超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.617 hours\n"
     ]
    }
   ],
   "source": [
    "# LR模型只有一个超参数C。使用 pipeline，将 “标准化StandardScaler”和“LR模型”组成管道。\n",
    "# 通过GridSearchCV对训练集X_tr_train，y_tr_train进行5折交叉验证，从而实现对LR的超参数C进行\n",
    "# 交叉验证，选出最佳C。\n",
    "\n",
    "# ks_score = make_scorer(ks_statistic,greater_is_better=True,needs_proba=False)\n",
    "LR_parameter = {\"penalty\": \"l2\",\"tol\": 1e-4,\"class_weight\": 'balanced', \n",
    "                'solver': 'liblinear','max_iter':100,'random_state':3}\n",
    "pipe1 = Pipeline([ (\"standard\", StandardScaler()) ,\n",
    "                  (\"LR\", LogisticRegression(**LR_parameter)) ])\n",
    "\n",
    "# 只对C这一个超参数进行网格搜索。给出C的粗范围。\n",
    "param_grid = dict(LR__C=[0.001,0.01,0.1, 1, 10, 100, 1000]) \n",
    "\n",
    "# scoring指定了多个函数，则交叉验证会算多个score。而应该依据哪个函数的返回值来选择最佳超参数？在refit里指定。\n",
    "timestart = time.time()\n",
    "grid_search = GridSearchCV( pipe1, param_grid=param_grid, cv=5, scoring=\"roc_auc\", refit=\"roc_auc\")  \n",
    "grid_search.fit(X_tr_train,y_tr_train)\n",
    "print(\"Time: {:.3f} hours\".format((time.time() - timestart)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR__C': 0.01}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回最佳超参数值，可见最佳C是0.01\n",
    "grid_search.best_params_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3 对验证集进行预测并求得AUC---法1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行预测。法1  \n",
    "  \n",
    "说明：  \n",
    "&ensp;&ensp;我是这样理解的，GridSearchCV 去 fit(X_tr_train,y_tr_train)时，首先按照cv=5的要求分成五折（按照GridSearchCV的规定，是分层抽样但不随机shuffle。好在我刚开始已经手动shuffle过了。则这样实现了“shuffle+分层”的抽样方法），然后，把第一种情况（4折训练集，1折验证集）包括它们对应的目标y值传给pipe，pipe里的StandardScaler先接触到 4折训练集+1折验证集，StandardScaler会对4折训练集进行 fit+transform标准化，然后把学到的均值方差应用到1折验证集上，对其也标准化（应该不会对目标变量y进行标准化，因为，查阅StandardScaler的文档，发现它的fit方法的参数里是有y的，但不会对y进行任何处理，我认为是StandardScaler为了兼容其它方法，比如这里的pipeline，还是保留了y参数，从而有一个传递的效果），然后，标准化后的4折训练集+1折验证集，以及不变的y 传递给LR模型，而且此时GridSearchCV 选定尝试超参数C=0.001，LR模型进行训练，得到在C=0.001下的模型，并对验证集进行预测，对比验证集真实结果，用scoring=”roc_auc”即auc标准，算得auc值。 后续过程参见GridSearchCV原理。总之，GridSearchCV会对每个超参数组合进行5次训练，得到5个score取平均，谁的平均score最高，则谁是最佳的超参数C值。  \n",
    "&ensp;&ensp;grid_search.best_params_ 返回这个最佳C。  \n",
    "&ensp;&ensp;另外，因为GridSearchCV设置 refit=true，所以得到最佳C后，会在整个数据集上再尝试，这时，整个数据集X_tr_train,y_tr_train给到了StandardScaler，它直接将X_tr_train标准化，保留y_tr_train不变，并记录了X_tr_train的均值方差标准。然后，把标准化的X_tr_train,y_tr_train给到了LR模型，在最佳C下对整个训练集训练出模型，这个模型存储在grid_search.best_estimator_。另外我认为，对于 GridSearchCV来说，“模型”这个概念指的是pipe，毕竟GridSearchCV的第一个参数我写的是pipe而非LR，所以，我认为这个最佳模型应该是pipe，即包含了StandardScaler和LR，其中，StandardScaler是对标准化的整个训练集进行fit得到的，所以我认为它里面是包含了整个训练集的均值方差。而LR是对整个标准化训练集在C为最佳C下训练得到的。  \n",
    "&ensp;&ensp;然后，grid_search. predict_proba(X_tr_test)会用这个存储在grid_search.best_estimator_里的模型预测测试集X_tr_test，因为StandardScaler已经存储了整个训练集的均值方差，所以可以直接用在X_tr_test上。这样是对的。然后，把标准化后的X_tr_test传递给最佳LR模型，进行预测。  \n",
    "&ensp;&ensp;grid_search. score(X_tr_test,y_tr_test) 同样是用grid_search.best_estimator_里的最佳模型对X_tr_test进行标准化，预测，评分，这里用的是scoring=”roc_auc”定义的auc分值。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standard', StandardScaler(copy=True, with_mean=True, with_std=True)), ('LR', LogisticRegression(C=0.01, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=3,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回最佳模型。是在最佳超参数 C= 下，对整个训练集 X_tr_train，y_tr_train进行学习得到的模型。\n",
    "grid_search.best_estimator_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6687085665187095"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回使用最佳超参数值进行五折训练时，得到的 5个score的均值，且是 refit指定的 auc指标的均值。\n",
    "# 可见，最佳C时，五折训练得到的五个模型对各自验证集预测的auc得分的均值为 0.6687 。\n",
    "grid_search.best_score_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57849826, 0.42150174],\n",
       "       [0.54401289, 0.45598711],\n",
       "       [0.56817054, 0.43182946],\n",
       "       ...,\n",
       "       [0.75230456, 0.24769544],\n",
       "       [0.57148205, 0.42851795],\n",
       "       [0.79973481, 0.20026519]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对测试集 X_tr_test 进行属于正类别1的概率预测\n",
    "grid_search.predict_proba(X_tr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6736258454927472"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用best_estimator_里的最佳模型对测试集样本进行预测并计算score。score指标使用 refit指定的auc指标。\n",
    "# 可见，最佳模型对测试集预测的auc是0.67左右。\n",
    "grid_search.score(X_tr_test,y_tr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ks_value is:  0.2531851273014329\n"
     ]
    }
   ],
   "source": [
    "# 算一下 ks 评分。可见， KS评分还是很低的。\n",
    "ks_value = ks_statistic(np.array(y_tr_test),grid_search.predict_proba(X_tr_test)[:,1])\n",
    "# 注意此处，千万不要把 左侧的变量的名字定义为 ks_statistic，否则算出值后，此变量会指向一个值，而非一个函数。\n",
    "# 下一次再调用 ks_statistic时就会出错。犯过这个错了已经。\n",
    "print(\"ks_value is: \",ks_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.4 对验证集进行预测并求得AUC---法2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行预测。法2  \n",
    "  \n",
    "说明：  \n",
    "&ensp;&ensp;grid_search.best_params_ 得到了最佳C。然后，将之带入到pipe中，这时，pipe里的LR模型的C就固定了，然后，pipe.fit(X_tr_train,y_tr_train)，首先，StandardScaler接触到X_tr_train,y_tr_train，会对X_tr_train进行fit和transform，即进行标准化并记录X_tr_train的均值方差。然后，把标准化后的X_tr_train和未更改的y_tr_train给到LR，则LR会在最佳C下fit此数据，得到最佳模型。    \n",
    "&ensp;&ensp;pipe.predict_proba(X_tr_test)是用次最佳模型对X_tr_test进行预测，首先还是StandardScaler接触到X_tr_test，但它已经存储了X_tr_train的均值方差，所以直接应用到X_tr_test上即可，然后把标准化的X_tr_test给到了LR模型进行预测。  \n",
    "&ensp;&ensp;然后调用 roc函数计算auc。  \n",
    "&ensp;&ensp;我个人认为法1和法2的predict_proba 和 auc 结果应该是相同的。事实却是是相同的。证明法1法2等效。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR__C': 0.01}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回最佳超参数值，可见最佳C是0.01\n",
    "grid_search.best_params_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57849826, 0.42150174],\n",
       "       [0.54401289, 0.45598711],\n",
       "       [0.56817054, 0.43182946],\n",
       "       ...,\n",
       "       [0.75230456, 0.24769544],\n",
       "       [0.57148205, 0.42851795],\n",
       "       [0.79973481, 0.20026519]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这里使用了将 C值代入 pipe，得到最终 pipe的方式。用 pipe 对测试集样本进行预测，计算auc。\n",
    "\n",
    "pipe1.set_params(LR__C=0.01)  # 最佳超参数值代入pipe里\n",
    "pipe1.fit(X_tr_train,y_tr_train)  # 整个训练集 X_tr_train，y_tr_train进行学习得到的模型\n",
    "pipe1.predict_proba(X_tr_test) # 可见这个结果和法 1 完全相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6736258454927472"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可见这个结果和法 1 完全相同。\n",
    "roc_auc_score(y_tr_test, pipe1.predict_proba(X_tr_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ks_statistic value is:  0.2531851273014329\n"
     ]
    }
   ],
   "source": [
    "# 算一下 ks 评分。KS评分与法1相同，还是很低的。\n",
    "\n",
    "ks_value2 = ks_statistic(np.array(y_tr_test),pipe1.predict_proba(X_tr_test)[:,1]) \n",
    "print(\"ks_statistic value is: \",ks_value2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.5 查看并分析详细信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.6 hyperopt 求取最佳超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&ensp;&ensp;GridSearchCV只是求出了超参数C的大致范围，即0.001到0.1之间。我们把C的范围限制在这里，通过hyperopt在这个参数范围内寻找最佳C值。首先，使用训练LR时使用的二八分数据：训练集X_tr_train，y_tr_train, 测试集X_tr_test，y_tr_test。按照hyperopt的用法，需要自定义一个函数，给出超参数范围，hyperopt在这个范围内选择值，然后代入这个函数，求得函数值，使函数值最小的那个就是最佳超参数。我们这样定义函数LRfunction：对训练集X_tr_train，y_tr_train进行五折划分，在某C下，分别学得5个模型，用模型对各自的测试集预测并求auc，求得5个auc值的均值的负数，作为函数返回值，可见，此值越小，说明 auc均值越大，说明这个C固定值越佳。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_tr_train is: (44304, 424)\n",
      "shape of y_tr_train is: (44304,)\n",
      "shape of X_tr_test is: (11077, 424)\n",
      "shape of y_tr_test is: (11077,)\n"
     ]
    }
   ],
   "source": [
    "# 使用训练LR模型使用的二八分数据：训练集X_tr_train，y_tr_train, 测试集X_tr_test，y_tr_test\n",
    "\n",
    "print(\"shape of X_tr_train is:\",X_tr_train.shape)\n",
    "print(\"shape of y_tr_train is:\",y_tr_train.shape)\n",
    "print(\"shape of X_tr_test is:\",X_tr_test.shape)\n",
    "print(\"shape of y_tr_test is:\",y_tr_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后，对训练集X_tr_train，y_tr_train进行一次性五折划分。\n",
    "# Xt 存储了 5个二维array，分别是5份训练集。  \n",
    "# Xv 存储了 5个二维array，分别是对应的5份验证集。\n",
    "# Yt 存储了 5个一维array，分别是对应的5份训练集的标签。\n",
    "# Yv 存储了 5个一维array，分别是对应的5份验证集的标签。\n",
    "\n",
    "\n",
    "skf = StratifiedKFold (n_splits=5,shuffle=True,random_state=2)  \n",
    "# 保证了即shuffle又分层。（其实二八分时已经shuffle过了，此处可以不shuffle，也可以再shuffle一次）\n",
    "Xt = []\n",
    "Yt = []\n",
    "Xv = []\n",
    "Yv = []\n",
    "for train_index, validation_index in skf.split(X_tr_train.values,y_tr_train.values):  \n",
    "    Xt.append(X_tr_train.values[train_index])\n",
    "    Yt.append(y_tr_train.values[train_index])\n",
    "    Xv.append(X_tr_train.values[validation_index])\n",
    "    Yv.append(y_tr_train.values[validation_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         5.00000000e+00, 6.05015990e+01, 5.93161749e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         4.00000000e+00, 4.14421640e+01, 5.92919829e+09],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "         3.00000000e+00, 4.38137420e+01, 5.92911189e+09],\n",
       "        ...,\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         8.00000000e+00, 1.54479904e+02, 5.92686549e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.00000000e+00, 4.01248630e+01, 5.92755669e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         7.00000000e+00, 1.22143875e+02, 5.92695189e+09]]),\n",
       " array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.00000000e+00, 4.26317480e+01, 5.91563349e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.00000000e+00, 3.98147080e+01, 5.92824789e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         4.00000000e+00, 4.14421640e+01, 5.92919829e+09],\n",
       "        ...,\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         4.00000000e+00, 8.44982210e+01, 5.92781589e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         9.00000000e+00, 1.67882901e+02, 5.92703829e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.00000000e+00, 4.01248630e+01, 5.92755669e+09]]),\n",
       " array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.00000000e+00, 4.26317480e+01, 5.91563349e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         5.00000000e+00, 6.05015990e+01, 5.93161749e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.00000000e+00, 3.98147080e+01, 5.92824789e+09],\n",
       "        ...,\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         8.00000000e+00, 1.54479904e+02, 5.92686549e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.00000000e+00, 4.01248630e+01, 5.92755669e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         7.00000000e+00, 1.22143875e+02, 5.92695189e+09]]),\n",
       " array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.00000000e+00, 4.26317480e+01, 5.91563349e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         5.00000000e+00, 6.05015990e+01, 5.93161749e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.00000000e+00, 3.98147080e+01, 5.92824789e+09],\n",
       "        ...,\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         9.00000000e+00, 1.67882901e+02, 5.92703829e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         8.00000000e+00, 1.54479904e+02, 5.92686549e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         7.00000000e+00, 1.22143875e+02, 5.92695189e+09]]),\n",
       " array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.00000000e+00, 4.26317480e+01, 5.91563349e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         5.00000000e+00, 6.05015990e+01, 5.93161749e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.00000000e+00, 3.98147080e+01, 5.92824789e+09],\n",
       "        ...,\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         8.00000000e+00, 1.54479904e+02, 5.92686549e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.00000000e+00, 4.01248630e+01, 5.92755669e+09],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         7.00000000e+00, 1.22143875e+02, 5.92695189e+09]])]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " array([0., 0., 0., ..., 0., 0., 1.]),\n",
       " array([0., 0., 0., ..., 0., 0., 1.])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.875 hours\n"
     ]
    }
   ],
   "source": [
    "# 此段代码用 hyperopt 加 交叉验证 选择 LR 模型的最优超参数。\n",
    "#（5折交叉验证）将此训练集一次性随机分成5份，以其中4份作为训练集，1份作为验证集。给模型代入一组固定的超参数值，然后，\n",
    "# 用此模型对这4份训练集进行学习，用学得的模型对那1份验证集进行预测，然后，对比验证集的预测值和真实值（用Score函数，计算AUC值），\n",
    "# 得到score。因为是5折，所以可以学得5个模型，进行5次相应预测，得到5个score值（这5个模型用的都是同一组超参数值），\n",
    "# 求这5个score的平均值的负值，即 -np.mean(score)。将这个过程构成函数 LRfunction，这个-np.mean(score)就是LRfunction的返回值，\n",
    "# 是hyperopt的评价依据。然后，定义超参数空间space，设置搜索算法algo参数，然后，使用fmin方法在超参数空间中选择能使 -np.mean(score)\n",
    "# 值最小的那组超参数值。这样，就得到了最佳超参数值。\n",
    "# 此处，LR 模型 只用 hyperopt 加 交叉验证 选择 \"C\" 这一个超参数的最优值。\n",
    "# 另外，还使用了 trials 捕捉了在每一次尝试中使用的 C值 和 对应得到 的-np.mean(score)值（即loss列）\n",
    "\n",
    "\n",
    "LR_parameter_space ={'C':hp.uniform('C', 0.001, 0.1)}  \n",
    "# \n",
    "# 对 LR 模型来说，只对 C 这一个超参数调参。我本来用的是 hp.loguniform(\"C\", -6.9, -2.3)，\n",
    "# 这个根据粗选结果来设定。exp(-6.9)=0.001, exp(-4.6)=0.01,  exp(-2.3)=0.1 \n",
    "# [exp(-6.9),exp(-2.3)]间的log分布。但我发现这样不太好，因为这个分布对 0.001到0.01之间的数值\n",
    "# 尝试的比较多，而对 0.01到 0.1 之间的尝试的很少。所以我改成了均匀分布。\n",
    "\n",
    "\n",
    "def LRfunction(args):\n",
    "    # args是LR_parameter_space\n",
    "    LR_parameter = {\"penalty\": \"l2\", \"class_weight\": 'balanced', 'solver': 'liblinear',\n",
    "                    'random_state':5,'max_iter':100,'tol':0.005} \n",
    "                    # 这个随机数是因为liblinear使用了随机过程。另外max_iter需要增加么？\n",
    "    LR_parameter.update(args)\n",
    "    clf = LogisticRegression(**LR_parameter)\n",
    "   \n",
    "    score = []\n",
    "    for i in range(len(Xt)):\n",
    "        # 标准化数据集\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(Xt[i])\n",
    "        Xti_std = scaler.transform(Xt[i])  # std表示标准化过\n",
    "        Xvi_std = scaler.transform(Xv[i])\n",
    "        # 训练模型\n",
    "        clf.fit(Xti_std,Yt[i])\n",
    "        # 若此时 print('LR_classes:',clf.classes_) ， 结果为：array([0, 1], dtype=int64)，即类别 0 先，类别 1 后。\n",
    "        # 预测验证集\n",
    "        proba_prediction = clf.predict_proba(Xvi_std)\n",
    "        # 所得到的 proba_prediction 是一个 二维 array，第一列是预测每个样属于第 0 类的概率，\n",
    "        # 第二列是每个样属于第1类的概率。(与clf.classes_ 顺序保持一致)\n",
    "        \n",
    "        score.append(roc_auc_score(Yv[i],proba_prediction[:,1]))  \n",
    "        # 所以这里是 proba_prediction[:,1] 取第二列。\n",
    "  \n",
    "    return -np.mean(score)\n",
    "\n",
    "timestart = time.time()\n",
    "LRtrials = Trials()\n",
    "LRbest = fmin(fn = LRfunction, space = LR_parameter_space, algo=tpe.suggest, max_evals=30,trials=LRtrials)  # max_evals表示尝试30个C值，从中找最好的。可以先设为2，尝试一下。\n",
    "print(\"Time: {:.3f} hours\".format((time.time() - timestart)/3600))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book_time': datetime.datetime(2019, 5, 5, 14, 28, 31, 871000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [0]},\n",
       "   'tid': 0,\n",
       "   'vals': {'C': [0.051312253891688836]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 30, 38, 921000),\n",
       "  'result': {'loss': -0.6647268659759156, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 0,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 30, 38, 926000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [1]},\n",
       "   'tid': 1,\n",
       "   'vals': {'C': [0.01583310860869715]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 32, 4, 227000),\n",
       "  'result': {'loss': -0.6660431043411293, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 1,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 32, 4, 235000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [2]},\n",
       "   'tid': 2,\n",
       "   'vals': {'C': [0.017728129005336178]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 33, 29, 639000),\n",
       "  'result': {'loss': -0.6659048687503877, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 2,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 33, 29, 655000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [3]},\n",
       "   'tid': 3,\n",
       "   'vals': {'C': [0.03446401097523321]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 35, 32, 295000),\n",
       "  'result': {'loss': -0.6651531747929157, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 3,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 35, 32, 297000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [4]},\n",
       "   'tid': 4,\n",
       "   'vals': {'C': [0.034779028548396713]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 37, 35, 364000),\n",
       "  'result': {'loss': -0.6651488012910984, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 4,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 37, 35, 366000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [5]},\n",
       "   'tid': 5,\n",
       "   'vals': {'C': [0.024294284619780462]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 39, 14, 495000),\n",
       "  'result': {'loss': -0.6655512344049385, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 5,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 39, 14, 498000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [6]},\n",
       "   'tid': 6,\n",
       "   'vals': {'C': [0.08234522803894641]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 41, 41, 405000),\n",
       "  'result': {'loss': -0.6642534105303828, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 6,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 41, 41, 407000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [7]},\n",
       "   'tid': 7,\n",
       "   'vals': {'C': [0.03832471442617086]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 43, 42, 871000),\n",
       "  'result': {'loss': -0.665045976036176, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 7,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 43, 42, 873000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [8]},\n",
       "   'tid': 8,\n",
       "   'vals': {'C': [0.027195775868923126]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 45, 26, 642000),\n",
       "  'result': {'loss': -0.6654222129425611, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 8,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 45, 26, 644000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [9]},\n",
       "   'tid': 9,\n",
       "   'vals': {'C': [0.007289728021887563]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 46, 36, 93000),\n",
       "  'result': {'loss': -0.6666950808800338, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 9,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 46, 36, 95000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [10]},\n",
       "   'tid': 10,\n",
       "   'vals': {'C': [0.03461540459310564]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 48, 39, 399000),\n",
       "  'result': {'loss': -0.6651505011285825, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 10,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 48, 39, 401000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [11]},\n",
       "   'tid': 11,\n",
       "   'vals': {'C': [0.06937590282470797]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 50, 41, 442000),\n",
       "  'result': {'loss': -0.6644099103175451, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 11,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 50, 41, 444000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [12]},\n",
       "   'tid': 12,\n",
       "   'vals': {'C': [0.0220883343318498]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 52, 15, 407000),\n",
       "  'result': {'loss': -0.6656660688433936, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 12,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 52, 15, 409000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [13]},\n",
       "   'tid': 13,\n",
       "   'vals': {'C': [0.09462501005145019]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 54, 49, 706000),\n",
       "  'result': {'loss': -0.664140182869174, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 13,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 54, 49, 712000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [14]},\n",
       "   'tid': 14,\n",
       "   'vals': {'C': [0.08456452876699758]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 57, 22, 664000),\n",
       "  'result': {'loss': -0.664233929155664, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 14,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 57, 22, 669000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [15]},\n",
       "   'tid': 15,\n",
       "   'vals': {'C': [0.047226240963521196]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 14, 59, 24, 561000),\n",
       "  'result': {'loss': -0.6648171686495639, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 15,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 14, 59, 24, 563000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [16]},\n",
       "   'tid': 16,\n",
       "   'vals': {'C': [0.0025687032236708135]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 0, 15, 699000),\n",
       "  'result': {'loss': -0.666901524574961, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 16,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 15, 0, 15, 701000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [17]},\n",
       "   'tid': 17,\n",
       "   'vals': {'C': [0.07346306533858081]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 2, 15, 569000),\n",
       "  'result': {'loss': -0.6643586950404371, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 17,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 15, 2, 15, 571000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [18]},\n",
       "   'tid': 18,\n",
       "   'vals': {'C': [0.03618361883423608]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 4, 14, 841000),\n",
       "  'result': {'loss': -0.6651072983638426, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 18,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 15, 4, 14, 844000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [19]},\n",
       "   'tid': 19,\n",
       "   'vals': {'C': [0.0517412189907326]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 6, 15, 294000),\n",
       "  'result': {'loss': -0.6647102143884753, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 19,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 15, 6, 15, 323000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [20]},\n",
       "   'tid': 20,\n",
       "   'vals': {'C': [0.0025380552761901255]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 7, 3, 558000),\n",
       "  'result': {'loss': -0.666890447910247, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 20,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 15, 7, 3, 565000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [21]},\n",
       "   'tid': 21,\n",
       "   'vals': {'C': [0.002205087299347916]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 7, 51, 536000),\n",
       "  'result': {'loss': -0.6668263740678626, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 21,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 15, 7, 51, 546000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [22]},\n",
       "   'tid': 22,\n",
       "   'vals': {'C': [0.007139469917247696]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 8, 55, 48000),\n",
       "  'result': {'loss': -0.6667191857579353, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 22,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 15, 8, 55, 58000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [23]},\n",
       "   'tid': 23,\n",
       "   'vals': {'C': [0.002956614147662452]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 9, 45, 539000),\n",
       "  'result': {'loss': -0.666941884502366, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 23,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 15, 9, 45, 549000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [24]},\n",
       "   'tid': 24,\n",
       "   'vals': {'C': [0.01262482269672511]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 11, 5, 966000),\n",
       "  'result': {'loss': -0.6662714640934977, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 24,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 15, 11, 5, 975000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [25]},\n",
       "   'tid': 25,\n",
       "   'vals': {'C': [0.010578512854457319]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 12, 27, 991000),\n",
       "  'result': {'loss': -0.6664307211684525, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 25,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 15, 12, 28, 1000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [26]},\n",
       "   'tid': 26,\n",
       "   'vals': {'C': [0.05970937721145801]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 14, 57, 850000),\n",
       "  'result': {'loss': -0.6645608094885601, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 26,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 15, 14, 57, 862000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [27]},\n",
       "   'tid': 27,\n",
       "   'vals': {'C': [0.00331555696165052]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 15, 59, 14000),\n",
       "  'result': {'loss': -0.6669598648020906, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 27,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 15, 15, 59, 31000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [28]},\n",
       "   'tid': 28,\n",
       "   'vals': {'C': [0.026822826061418784]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 18, 6, 698000),\n",
       "  'result': {'loss': -0.6654348995531414, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 28,\n",
       "  'version': 0},\n",
       " {'book_time': datetime.datetime(2019, 5, 5, 15, 18, 6, 712000),\n",
       "  'exp_key': None,\n",
       "  'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'idxs': {'C': [29]},\n",
       "   'tid': 29,\n",
       "   'vals': {'C': [0.04515912679182521]},\n",
       "   'workdir': None},\n",
       "  'owner': None,\n",
       "  'refresh_time': datetime.datetime(2019, 5, 5, 15, 21, 1, 199000),\n",
       "  'result': {'loss': -0.6648630872833035, 'status': 'ok'},\n",
       "  'spec': None,\n",
       "  'state': 2,\n",
       "  'tid': 29,\n",
       "  'version': 0}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这里记录了 hyperopt 在循环计算时的详细情况。因为 fmin中max_evals=30，也就是要从给出的C的范围（space参数）里选出30个C值进行试验。\n",
    "# LRtrials.trials 是一个 list，里面有三个字典，即尝试 30 个C值时的详细情况。\n",
    "# 每个字典里，misc是一个复合字典，里面的 vals 记录了尝试的 C值。\n",
    "\n",
    "LRtrials.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.6647268659759156,\n",
       " -0.6660431043411293,\n",
       " -0.6659048687503877,\n",
       " -0.6651531747929157,\n",
       " -0.6651488012910984,\n",
       " -0.6655512344049385,\n",
       " -0.6642534105303828,\n",
       " -0.665045976036176,\n",
       " -0.6654222129425611,\n",
       " -0.6666950808800338,\n",
       " -0.6651505011285825,\n",
       " -0.6644099103175451,\n",
       " -0.6656660688433936,\n",
       " -0.664140182869174,\n",
       " -0.664233929155664,\n",
       " -0.6648171686495639,\n",
       " -0.666901524574961,\n",
       " -0.6643586950404371,\n",
       " -0.6651072983638426,\n",
       " -0.6647102143884753,\n",
       " -0.666890447910247,\n",
       " -0.6668263740678626,\n",
       " -0.6667191857579353,\n",
       " -0.666941884502366,\n",
       " -0.6662714640934977,\n",
       " -0.6664307211684525,\n",
       " -0.6645608094885601,\n",
       " -0.6669598648020906,\n",
       " -0.6654348995531414,\n",
       " -0.6648630872833035]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LRtrials.losses() 为一个 list，里面有30个值，分别是尝试每个C值时，LRfunction 的返回值，即 5折交叉验证求得的5个score的均值的负数。\n",
    "\n",
    "LRtrials.losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将结果组成 dataframe 表 LRop。\n",
    "# 第一列为 尝试的 C值，第二列是 将此C代入 LRfunction 后求出的 平均auc 值。此值越大，说明此 C 越佳。（已按auc_mean从大到小排序）\n",
    "# 使得 平均auc值最大的那个 C，就是 hyperopt 选出的最佳 C。即为首行 C 。\n",
    "\n",
    "LRop = pd.concat([pd.DataFrame([sum(list(LRtrials.trials[j][\"misc\"][\"vals\"].values()), []) for j in range(len(LRtrials))],\n",
    "                                 columns = list(LRtrials.trials[0][\"misc\"][\"vals\"].keys())),\n",
    "           pd.DataFrame({\"auc_mean\":[np.abs(i) for i in LRtrials.losses()]})], axis = 1).sort_values(by=[\"auc_mean\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>auc_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.666960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.666942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.666902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.666890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.666826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.666719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007290</td>\n",
       "      <td>0.666695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.010579</td>\n",
       "      <td>0.666431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.012625</td>\n",
       "      <td>0.666271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015833</td>\n",
       "      <td>0.666043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017728</td>\n",
       "      <td>0.665905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.022088</td>\n",
       "      <td>0.665666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.024294</td>\n",
       "      <td>0.665551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.026823</td>\n",
       "      <td>0.665435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.027196</td>\n",
       "      <td>0.665422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034464</td>\n",
       "      <td>0.665153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.034615</td>\n",
       "      <td>0.665151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034779</td>\n",
       "      <td>0.665149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.036184</td>\n",
       "      <td>0.665107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.038325</td>\n",
       "      <td>0.665046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.045159</td>\n",
       "      <td>0.664863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.047226</td>\n",
       "      <td>0.664817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051312</td>\n",
       "      <td>0.664727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.051741</td>\n",
       "      <td>0.664710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.059709</td>\n",
       "      <td>0.664561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.069376</td>\n",
       "      <td>0.664410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.073463</td>\n",
       "      <td>0.664359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.082345</td>\n",
       "      <td>0.664253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.084565</td>\n",
       "      <td>0.664234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.094625</td>\n",
       "      <td>0.664140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           C  auc_mean\n",
       "27  0.003316  0.666960\n",
       "23  0.002957  0.666942\n",
       "16  0.002569  0.666902\n",
       "20  0.002538  0.666890\n",
       "21  0.002205  0.666826\n",
       "22  0.007139  0.666719\n",
       "9   0.007290  0.666695\n",
       "25  0.010579  0.666431\n",
       "24  0.012625  0.666271\n",
       "1   0.015833  0.666043\n",
       "2   0.017728  0.665905\n",
       "12  0.022088  0.665666\n",
       "5   0.024294  0.665551\n",
       "28  0.026823  0.665435\n",
       "8   0.027196  0.665422\n",
       "3   0.034464  0.665153\n",
       "10  0.034615  0.665151\n",
       "4   0.034779  0.665149\n",
       "18  0.036184  0.665107\n",
       "7   0.038325  0.665046\n",
       "29  0.045159  0.664863\n",
       "15  0.047226  0.664817\n",
       "0   0.051312  0.664727\n",
       "19  0.051741  0.664710\n",
       "26  0.059709  0.664561\n",
       "11  0.069376  0.664410\n",
       "17  0.073463  0.664359\n",
       "6   0.082345  0.664253\n",
       "14  0.084565  0.664234\n",
       "13  0.094625  0.664140"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6742869445263973"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在我们已经确定出了最佳的C值：0.005。然后在最佳C下对整个训练集X_tr_train, y_tr_train进行学习，学得的模型对X_tr_test, y_tr_test 进行预测。\n",
    "# 可见，对验证集进行预测算auc，值为 0.67，并不高。ks 评分为0.25，也不高。\n",
    "\n",
    "args = {\"C\":0.005}\n",
    "LR_parameter = {\"penalty\": \"l2\", \"class_weight\": 'balanced', 'solver': 'liblinear',\n",
    "                'random_state':5,'max_iter':100,'tol':0.005} \n",
    "LR_parameter.update(args)\n",
    "\n",
    "# 之前 scaler2 已经 对 X_tr_train 和 X_tr_test 进行过了标准化如下，可以拿来直接用。\n",
    "# scaler2 = StandardScaler()\n",
    "# scaler2.fit(X_tr_train)\n",
    "# X_tr_train_standard = scaler2.transform(X_tr_train)\n",
    "# X_tr_test_standard = scaler2.transform(X_tr_test)\n",
    "\n",
    "modelLR3 = LogisticRegression(**LR_parameter)\n",
    "modelLR3.fit(X_tr_train_standard, y_tr_train)\n",
    "proba_prediction3 = modelLR3.predict_proba(X_tr_test_standard)\n",
    "\n",
    "# 计算AUC\n",
    "roc_auc_score(y_tr_test, proba_prediction3[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25432697291306183"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 算一下KS评分。\n",
    "ks_statistic(np.array(y_tr_test), proba_prediction3[:,1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.7 交叉验证  \n",
    "&ensp;&ensp;以上过程是建立在一次性二八分，用八份去通过GridSearchCV+hyperopt得到最佳C，然后在此C下对这八份进行学习得到最佳模型，然后用最佳模型对那三份进行预测并计算AUC和KS。  \n",
    "&ensp;&ensp;一次性二八分会否太单一？我认为可以在此C下使用交叉验证，多算几个验证分数。也就是把整个训练集X_tr, y_tr进行五折划分，在此C下学得5个模型，这5个模型对各自的验证集进行预测，得到5个auc和ks评分。可以看看这5个评分，算一下均分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5Fold scores : [0.66117415 0.67825853 0.66142954 0.6396072  0.63259252]\n",
      "5Fold mean score : 0.6546123878170597\n"
     ]
    }
   ],
   "source": [
    "# 使用 cross_val_score 进行交叉验证\n",
    "# 交叉验证显示，在最佳C下，训练的LR模型所得的auc评分也还在 0.65 左右，比较低。\n",
    "\n",
    "pipe2 = make_pipeline(StandardScaler(), LogisticRegression(**LR_parameter))  # LR_parameter 是固定参数+最佳超参数 C\n",
    "scores = cross_val_score(pipe2, X_tr, y_tr,cv = 5, scoring=\"roc_auc\")  # 或试试cv=10\n",
    "print(\"5Fold scores :\", scores)\n",
    "print(\"5Fold mean score :\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.8 训练最终LR模型并预测未知样本集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练最终LR模型并预测未知样本集\n",
    "\n",
    "scaler3=StandardScaler()\n",
    "scaler3.fit(X_tr)\n",
    "X_tr_std = scaler3.transform(X_tr)  # std代表标准化\n",
    "X_te_std = scaler3.transform(X_te)\n",
    "modelLR4 = LogisticRegression(**LR_parameter) # LR_parameter 是固定参数+最佳超参数 C\n",
    "modelLR4.fit(X_tr_std, y_tr)\n",
    "proba_prediction4 = modelLR4.predict_proba(X_te_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测结果整合成表\n",
    "\n",
    "LRpre = pd.DataFrame(proba_prediction4[:,1],index=X_te.index,columns=[\"positive_proba\"]).reset_index()\n",
    "LRpre.columns = [\"userid\",\"probability\"]  # 按官网提交示例修改列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存预测结果\n",
    "\n",
    "LRpre.to_csv(r'F:\\RiskPre2\\result\\LRpre.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:\\\\RiskPre2\\\\result\\\\modelLR4.pkl']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型\n",
    "\n",
    "joblib.dump(modelLR4, r'F:\\RiskPre2\\result\\modelLR4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存字段变量部分 X 和目标变量部分 Y 分开的： X_tr, y_tr, X_te, y_te\n",
    "\n",
    "f1 = open(r'F:\\RiskPre2\\result\\data_fill_XY.pkl', \"wb\")\n",
    "pickle.dump(X_tr, f1, protocol=-1)\n",
    "pickle.dump(y_tr, f1, protocol=-1)\n",
    "pickle.dump(X_te, f1, protocol=-1)\n",
    "pickle.dump(y_te, f1, protocol=-1)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练集X_tr, y_tr进行二八划分得到的： X_tr_train, X_tr_test, y_tr_train, y_tr_test\n",
    "\n",
    "f2 = open(r'F:\\RiskPre2\\result\\split2_8.pkl', \"wb\")\n",
    "pickle.dump(X_tr_train, f2, protocol=-1)\n",
    "pickle.dump(y_tr_train, f2, protocol=-1)\n",
    "pickle.dump(X_tr_test, f2, protocol=-1)\n",
    "pickle.dump(y_tr_test, f2, protocol=-1)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "430px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
