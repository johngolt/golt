{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四章：迭代器与生成器\n",
    " 迭代是Python最强大的功能之一。初看起来，你可能会简单的认为迭代只不过是处理序列中元素的一种方法。\n",
    "然而，绝非仅仅就是如此，还有很多你可能不知道的，\n",
    "比如创建你自己的迭代器对象，在itertools模块中使用有用的迭代模式，构造生成器函数等等。\n",
    "这一章目的就是向你展示跟迭代有关的各种常见问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "你想在多个对象执行相同的操作，但是这些对象在不同的容器中，你希望代码在不失可读性的情况下避免写重复的循环。\n",
    "\n",
    "itertools.chain() 方法可以用来简化这个任务。\n",
    "它接受一个可迭代对象列表作为输入，并返回一个迭代器，有效的屏蔽掉在多个容器中迭代细节。\n",
    "from itertools import chain\n",
    "a = [1, 2, 3, 4]\n",
    "b = ['x', 'y', 'z']\n",
    "for x in chain(a, b):\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 4.13 创建数据处理管道\n",
    "\n",
    "\n",
    "### 问题\n",
    "\n",
    "\n",
    "你想以数据管道(类似Unix管道)的方式迭代处理数据。\n",
    "比如，你有个大量的数据需要处理，但是不能将它们一次性放入内存中。\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "\n",
    "生成器函数是一个实现管道机制的好办法。\n",
    "为了演示，假定你要处理一个非常大的日志文件目录："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo/\n",
    "    access-log-012007.gz\n",
    "    access-log-022007.gz\n",
    "    access-log-032007.gz\n",
    "    ...\n",
    "    access-log-012008\n",
    "bar/\n",
    "    access-log-092007.bz2\n",
    "    ...\n",
    "    access-log-022008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设每个日志文件包含这样的数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
    "210.212.209.67 - - [10/Jul/2012:00:18:51 -0500] \"GET /ply/ ...\" 200 11875\n",
    "210.212.209.67 - - [10/Jul/2012:00:18:51 -0500] \"GET /favicon.ico ...\" 404 369\n",
    "61.135.216.105 - - [10/Jul/2012:00:20:04 -0500] \"GET /blog/atom.xml ...\" 304 -\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了处理这些文件，你可以定义一个由多个执行特定任务独立任务的简单生成器函数组成的容器。就像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import gzip\n",
    "import bz2\n",
    "import re\n",
    "\n",
    "def gen_find(filepat, top):\n",
    "    '''\n",
    "    Find all filenames in a directory tree that match a shell wildcard pattern\n",
    "    '''\n",
    "    for path, dirlist, filelist in os.walk(top):\n",
    "        for name in fnmatch.filter(filelist, filepat):\n",
    "            yield os.path.join(path,name)\n",
    "\n",
    "def gen_opener(filenames):\n",
    "    '''\n",
    "    Open a sequence of filenames one at a time producing a file object.\n",
    "    The file is closed immediately when proceeding to the next iteration.\n",
    "    '''\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.gz'):\n",
    "            f = gzip.open(filename, 'rt')\n",
    "        elif filename.endswith('.bz2'):\n",
    "            f = bz2.open(filename, 'rt')\n",
    "        else:\n",
    "            f = open(filename, 'rt')\n",
    "        yield f\n",
    "        f.close()\n",
    "\n",
    "def gen_concatenate(iterators):\n",
    "    '''\n",
    "    Chain a sequence of iterators together into a single sequence.\n",
    "    '''\n",
    "    for it in iterators:\n",
    "        yield from it\n",
    "\n",
    "def gen_grep(pattern, lines):\n",
    "    '''\n",
    "    Look for a regex pattern in a sequence of lines\n",
    "    '''\n",
    "    pat = re.compile(pattern)\n",
    "    for line in lines:\n",
    "        if pat.search(line):\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在你可以很容易的将这些函数连起来创建一个处理管道。\n",
    "比如，为了查找包含单词python的所有日志行，你可以这样做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lognames = gen_find('access-log*', 'www')\n",
    "files = gen_opener(lognames)\n",
    "lines = gen_concatenate(files)\n",
    "pylines = gen_grep('(?i)python', lines)\n",
    "for line in pylines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果将来的时候你想扩展管道，你甚至可以在生成器表达式中包装数据。\n",
    "比如，下面这个版本计算出传输的字节数并计算其总和。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lognames = gen_find('access-log*', 'www')\n",
    "files = gen_opener(lognames)\n",
    "lines = gen_concatenate(files)\n",
    "pylines = gen_grep('(?i)python', lines)\n",
    "bytecolumn = (line.rsplit(None,1)[1] for line in pylines)\n",
    "bytes = (int(x) for x in bytecolumn if x != '-')\n",
    "print('Total', sum(bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以管道方式处理数据可以用来解决各类其他问题，包括解析，读取实时数据，定时轮询等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了理解上述代码，重点是要明白 yield 语句作为数据的生产者而 for 循环语句作为数据的消费者。\n",
    "当这些生成器被连在一起后，每个 yield 会将一个单独的数据元素传递给迭代处理管道的下一阶段。\n",
    "在例子最后部分， sum() 函数是最终的程序驱动者，每次从生成器管道中提取出一个元素。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种方式一个非常好的特点是每个生成器函数很小并且都是独立的。这样的话就很容易编写和维护它们了。\n",
    "很多时候，这些函数如果比较通用的话可以在其他场景重复使用。\n",
    "并且最终将这些组件组合起来的代码看上去非常简单，也很容易理解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用这种方式的内存效率也不得不提。上述代码即便是在一个超大型文件目录中也能工作的很好。\n",
    "事实上，由于使用了迭代方式处理，代码运行过程中只需要很小很小的内存。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在调用 gen_concatenate() 函数的时候你可能会有些不太明白。\n",
    "这个函数的目的是将输入序列拼接成一个很长的行序列。\n",
    "itertools.chain() 函数同样有类似的功能，但是它需要将所有可迭代对象最为参数传入。\n",
    "在上面这个例子中，你可能会写类似这样的语句 lines = itertools.chain(*files) ，\n",
    "这将导致 gen_opener() 生成器被提前全部消费掉。\n",
    "但由于 gen_opener() 生成器每次生成一个打开过的文件，\n",
    "等到下一个迭代步骤时文件就关闭了，因此 chain() 在这里不能这样使用。\n",
    "上面的方案可以避免这种情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gen_concatenate() 函数中出现过 yield from 语句，它将 yield 操作代理到父生成器上去。\n",
    "语句 yield from it 简单的返回生成器 it 所产生的所有值。\n",
    "关于这个我们在4.14小节会有更进一步的描述。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后还有一点需要注意的是，管道方式并不是万能的。\n",
    "有时候你想立即处理所有数据。\n",
    "然而，即便是这种情况，使用生成器管道也可以将这类问题从逻辑上变为工作流的处理方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "David Beazley 在他的\n",
    "Generator Tricks for Systems Programmers\n",
    "教程中对于这种技术有非常深入的讲解。可以参考这个教程获取更多的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.14 展开嵌套的序列\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你想将一个多层嵌套的序列展开成一个单层列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解决方案\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以写一个包含 yield from 语句的递归生成器来轻松解决这个问题。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Iterable\n",
    "\n",
    "def flatten(items, ignore_types=(str, bytes)):\n",
    "    for x in items:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, ignore_types):\n",
    "            yield from flatten(x)\n",
    "        else:\n",
    "            yield x\n",
    "\n",
    "items = [1, 2, [3, 4, [5, 6], 7], 8]\n",
    "# Produces 1 2 3 4 5 6 7 8\n",
    "for x in flatten(items):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面代码中， isinstance(x, Iterable) 检查某个元素是否是可迭代的。\n",
    "如果是的话， yield from 就会返回所有子例程的值。最终返回结果就是一个没有嵌套的简单序列了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "额外的参数 ignore_types 和检测语句 isinstance(x, ignore_types)\n",
    "用来将字符串和字节排除在可迭代对象外，防止将它们再展开成单个的字符。\n",
    "这样的话字符串数组就能最终返回我们所期望的结果了。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ['Dave', 'Paula', ['Thomas', 'Lewis']]\n",
    "for x in flatten(items):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "语句 yield from 在你想在生成器中调用其他生成器作为子例程的时候非常有用。\n",
    "如果你不使用它的话，那么就必须写额外的 for 循环了。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(items, ignore_types=(str, bytes)):\n",
    "    for x in items:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, ignore_types):\n",
    "            for i in flatten(x):\n",
    "                yield i\n",
    "        else:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尽管只改了一点点，但是 yield from 语句看上去感觉更好，并且也使得代码更简洁清爽。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前提到的对于字符串和字节的额外检查是为了防止将它们再展开成单个字符。\n",
    "如果还有其他你不想展开的类型，修改参数 ignore_types 即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后要注意的一点是， yield from 在涉及到基于协程和生成器的并发编程中扮演着更加重要的角色。\n",
    "可以参考12.12小节查看另外一个例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.15 顺序迭代合并后的排序迭代对象\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你有一系列排序序列，想将它们合并后得到一个排序序列并在上面迭代遍历。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解决方案\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heapq.merge() 函数可以帮你解决这个问题。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "a = [1, 4, 7, 10]\n",
    "b = [2, 5, 6, 11]\n",
    "for c in heapq.merge(a, b):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heapq.merge 可迭代特性意味着它不会立马读取所有序列。\n",
    "这就意味着你可以在非常长的序列中使用它，而不会有太大的开销。\n",
    "比如，下面是一个例子来演示如何合并两个排序文件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sorted_file_1', 'rt') as file1, \\\n",
    "    open('sorted_file_2', 'rt') as file2, \\\n",
    "    open('merged_file', 'wt') as outf:\n",
    "\n",
    "    for line in heapq.merge(file1, file2):\n",
    "        outf.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一点要强调的是 heapq.merge() 需要所有输入序列必须是排过序的。\n",
    "特别的，它并不会预先读取所有数据到堆栈中或者预先排序，也不会对输入做任何的排序检测。\n",
    "它仅仅是检查所有序列的开始部分并返回最小的那个，这个过程一直会持续直到所有输入序列中的元素都被遍历完。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.16 迭代器代替while无限循环\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你在代码中使用 while 循环来迭代处理数据，因为它需要调用某个函数或者和一般迭代模式不同的测试条件。\n",
    "能不能用迭代器来重写这个循环呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解决方案\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个常见的IO操作程序可能会想下面这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKSIZE = 8192\n",
    "\n",
    "def reader(s):\n",
    "    while True:\n",
    "        data = s.recv(CHUNKSIZE)\n",
    "        if data == b'':\n",
    "            break\n",
    "        process_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种代码通常可以使用 iter() 来代替，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader2(s):\n",
    "    for chunk in iter(lambda: s.recv(CHUNKSIZE), b''):\n",
    "        pass\n",
    "        # process_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你怀疑它到底能不能正常工作，可以试验下一个简单的例子。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "f = open('/etc/passwd')\n",
    "for chunk in iter(lambda: f.read(10), ''):\n",
    "    n = sys.stdout.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iter 函数一个鲜为人知的特性是它接受一个可选的 callable 对象和一个标记(结尾)值作为输入参数。\n",
    "当以这种方式使用的时候，它会创建一个迭代器， 这个迭代器会不断调用 callable 对象直到返回值和标记值相等为止。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种特殊的方法对于一些特定的会被重复调用的函数很有效果，比如涉及到I/O调用的函数。\n",
    "举例来讲，如果你想从套接字或文件中以数据块的方式读取数据，通常你得要不断重复的执行 read() 或 recv() ，\n",
    "并在后面紧跟一个文件结尾测试来决定是否终止。这节中的方案使用一个简单的 iter() 调用就可以将两者结合起来了。\n",
    "其中 lambda 函数参数是为了创建一个无参的 callable 对象，并为 recv 或 read() 方法提供了 size 参数。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
