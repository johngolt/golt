{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Activation\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一个隐藏层\n",
    "model.add(Dense(units=64, input_dim=100))\n",
    "# 输入到输出之间的矩阵，权值向量\n",
    "model.add(Activation(\"relu\"))\n",
    "# 激活函数\n",
    "\n",
    "#输出层\n",
    "model.add(Dense(units=10))\n",
    "# 输出层的激活函数\n",
    "model.add(Activation(\"softmax\"))\n",
    "#编译模型时必须指明损失函数和优化器，如果你需要的话，也可以自己定制损失函数\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
    "# 评估模型\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n",
    "# 预测模型\n",
    "classes = model.predict(x_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.如何使Keras调用GPU？\n",
    "2.如何在多张GPU卡上使用Keras？\n",
    "3.如何获取中间层的输出？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "import theano\n",
    "theano.config.device = 'gpu'\n",
    "theano.config.floatX = 'float32'\n",
    "\n",
    "#2\n",
    "#2.1数据并行\n",
    "from keras.utils import multi_gpu_model\n",
    "# Replicates `model` on 8 GPUs.\n",
    "# This assumes that your machine has 8 available GPUs.\n",
    "parallel_model = multi_gpu_model(model, gpus=8)\n",
    "parallel_model.compile(loss='categorical_crossentropy',\n",
    "                       optimizer='rmsprop')\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "parallel_model.fit(x, y, epochs=20, batch_size=256)\n",
    "# 设备并行\n",
    "# Model where a shared LSTM is used to encode two different sequences in parallel\n",
    "input_a = keras.Input(shape=(140, 256))\n",
    "input_b = keras.Input(shape=(140, 256))\n",
    "\n",
    "shared_lstm = keras.layers.LSTM(64)\n",
    "\n",
    "# Process the first sequence on one GPU\n",
    "with tf.device_scope('/gpu:0'):\n",
    "    encoded_a = shared_lstm(tweet_a)\n",
    "# Process the next sequence on another GPU\n",
    "with tf.device_scope('/gpu:1'):\n",
    "    encoded_b = shared_lstm(tweet_b)\n",
    "\n",
    "# Concatenate results on CPU\n",
    "with tf.device_scope('/cpu:0'):\n",
    "    merged_vector = keras.layers.concatenate([encoded_a, encoded_b],\n",
    "                                             axis=-1)\n",
    "    \n",
    "#3\n",
    "from keras import backend as K\n",
    "\n",
    "# with a Sequential model\n",
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[3].output])\n",
    "layer_output = get_3rd_layer_output([X])[0]\n",
    "\n",
    "\n",
    "get_3rd_layer_output = K.function([model.layers[0].input, K.learning_phase()],\n",
    "                                  [model.layers[3].output])\n",
    "\n",
    "# output in test mode = 0\n",
    "layer_output = get_3rd_layer_output([X, 0])[0]\n",
    "\n",
    "# output in train mode = 1\n",
    "layer_output = get_3rd_layer_output([X, 1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#当验证集的loss不再下降时，如何中断训练？\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano模式会把100张RGB三通道的16×32（高为16宽为32）彩色图表示为下面这种形式（100,3,16,32）channels_first\n",
    "\n",
    "而TensorFlow，的表达形式是（100,16,32,3），即把通道维放在了最后，这种数据组织方式称为“channels_last”\n",
    "\n",
    "epochs指的就是训练过程中数据将被“轮”多少次\n",
    "一个epoch对应的就是网络的一轮更新。每一轮更新中网络更新的次数可以随意，但通常会设置为遍历一遍数据集。\n",
    "\n",
    "使用model.save(filepath)将Keras模型和权重保存在一个HDF5文件中\n",
    "模型的结构，以便重构该模型\n",
    "模型的权重\n",
    "训练配置（损失函数，优化器等）\n",
    "优化器的状态，以便于从上次训练中断的地方开始\n",
    "keras.models.load_model(filepath)来重新实例化你的模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显式的指定每个batch的大小。可以通过模型的首层参数batch_input_shape来完成。batch_input_shape是一个整数tuple，例如(32,10,16)代表一个具有10个时间步，每步向量长为16，每32个样本构成一个batch的输入数据格式。\n",
    "\n",
    "如何“冻结”网络的层？\n",
    "“冻结”一个层指的是该层将不参加网络训练，即该层的权重永不会更新。在进行fine-tune时我们经常会需要这项操作。 在使用固定的embedding层处理文本输入时，也需要这个技术。\n",
    "frozen_layer = Dense(32,trainable=False)\n",
    "\n",
    "如何从Sequential模型中去除一个层？\n",
    "可以通过调用.pop()来去除模型的最后一个层，反复调用n次即可去除模型后面的n个层\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(10, 16), batch_size=32, stateful=True))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# we train the network to predict the 11th timestep given the first 10:\n",
    "model.train_on_batch(X[:, :10, :], np.reshape(X[:, 10, :], (32, 16)))\n",
    "\n",
    "# the state of the network has changed. We can feed the follow-up sequences:\n",
    "model.train_on_batch(X[:, 10:20, :], np.reshape(X[:, 20, :], (32, 16)))\n",
    "\n",
    "# let's reset the states of the LSTM layer:\n",
    "model.reset_states()\n",
    "\n",
    "# another way to do it in this case:\n",
    "model.layers[0].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何在Keras中使用预训练的模型\n",
    "VGG16\n",
    "VGG19\n",
    "ResNet50\n",
    "Inception v3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/fchollet/keras/issues/2280#issuecomment-306959926\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(12345)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
